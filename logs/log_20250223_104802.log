[2025-02-23 10:48:02] Starting script execution.
[2025-02-23 10:48:02] Setting MAMBA_ROOT_PREFIX.
[2025-02-23 10:48:02] Running many layers with cv
Reading CSV files and subsampling...
Combined dataset shape: (900000, 421)
Filtering numeric features based on MAD...
Number of features kept after MAD filtering: 305
Splitting data into training and test sets...
Training set shape: (720000, 305), Test set shape: (180000, 305)
=== Building Pipeline & Grid Search (using NN with Val) ===
Starting GridSearchCV for the pipeline...
Fitting 3 folds for each of 24 candidates, totalling 72 fits
Model with 1 hidden layers and hidden_size 16 has 5049 trainable parameters.
Epoch [1/30] - Train Loss: 0.4083, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3161, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3009, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2890, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2833, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2777, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2737, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2709, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2691, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2673, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2656, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2641, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2632, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2623, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2617, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2607, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2593, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2590, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2581, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2575, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2571, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2569, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2557, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2547, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2551, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2538, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2541, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2538, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2532, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2531, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.001, nn__num_layers=1; total time=18.9min
Model with 1 hidden layers and hidden_size 16 has 5049 trainable parameters.
Epoch [1/30] - Train Loss: 0.4111, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3138, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2952, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2846, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2788, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2744, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2710, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2681, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2660, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2642, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2629, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2617, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2606, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2600, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2584, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2587, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2573, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2568, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2562, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2551, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2553, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2550, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2533, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2537, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2539, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2532, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2528, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2524, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2528, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2521, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.001, nn__num_layers=1; total time=17.3min
Model with 1 hidden layers and hidden_size 16 has 5049 trainable parameters.
Epoch [1/30] - Train Loss: 0.3962, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3054, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2894, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2818, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2765, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2725, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2700, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2673, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2654, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2634, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2619, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2610, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2593, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2588, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2584, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2571, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2565, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2557, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2555, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2547, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2539, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2534, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2528, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2521, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2518, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2521, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2516, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2510, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2507, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2505, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.001, nn__num_layers=1; total time=17.2min
Model with 2 hidden layers and hidden_size 16 has 5321 trainable parameters.
Epoch [1/30] - Train Loss: 0.3769, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2732, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2571, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2480, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2420, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2377, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2346, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2316, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2290, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2271, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2257, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2241, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2225, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2214, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2202, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2186, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2176, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2166, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2159, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2147, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2139, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2130, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2130, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2118, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2114, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2110, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2105, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2100, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2098, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2091, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.001, nn__num_layers=2; total time=18.6min
Model with 2 hidden layers and hidden_size 16 has 5321 trainable parameters.
Epoch [1/30] - Train Loss: 0.3884, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2823, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2638, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2535, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2467, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2426, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2386, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2357, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2331, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2320, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2301, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2291, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2280, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2270, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2261, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2253, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2242, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2239, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2228, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2228, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2226, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2211, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2208, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2202, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2198, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2191, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2188, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2183, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2181, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2174, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.001, nn__num_layers=2; total time=18.4min
Model with 2 hidden layers and hidden_size 16 has 5321 trainable parameters.
Epoch [1/30] - Train Loss: 0.3862, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2874, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2674, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2577, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2494, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2435, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2383, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2352, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2319, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2303, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2283, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2265, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2246, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2233, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2227, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2216, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2208, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2199, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2192, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2180, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2174, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2172, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2164, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2158, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2155, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2149, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2145, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2140, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2141, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2134, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.001, nn__num_layers=2; total time=18.3min
Model with 3 hidden layers and hidden_size 16 has 5593 trainable parameters.
Epoch [1/30] - Train Loss: 0.3941, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2828, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2580, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2461, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2391, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2341, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2303, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2276, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2248, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2215, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2194, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2173, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2160, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2148, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2131, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2126, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2113, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2100, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2101, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2090, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2081, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2071, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2066, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2062, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2056, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2049, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2042, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2038, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2029, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2024, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.001, nn__num_layers=3; total time=19.9min
Model with 3 hidden layers and hidden_size 16 has 5593 trainable parameters.
Epoch [1/30] - Train Loss: 0.4027, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2774, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2553, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2458, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2394, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2341, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2296, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2276, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2247, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2226, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2210, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2188, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2181, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2164, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2156, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2140, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2133, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2121, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2118, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2110, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2099, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2096, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2084, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2080, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2075, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2067, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2066, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2061, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2055, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2055, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.001, nn__num_layers=3; total time=20.5min
Model with 3 hidden layers and hidden_size 16 has 5593 trainable parameters.
Epoch [1/30] - Train Loss: 0.3913, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2843, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2628, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2501, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2417, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2360, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2315, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2281, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2249, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2226, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2202, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2184, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2168, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2156, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2142, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2127, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2114, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2103, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2095, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2086, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2080, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2070, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2064, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2055, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2051, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2041, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2040, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2037, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2032, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2029, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.001, nn__num_layers=3; total time=20.3min
Model with 1 hidden layers and hidden_size 16 has 5049 trainable parameters.
Epoch [1/30] - Train Loss: 0.6981, Val Loss: nan
Epoch [2/30] - Train Loss: 0.4017, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3614, Val Loss: nan
Epoch [4/30] - Train Loss: 0.3402, Val Loss: nan
Epoch [5/30] - Train Loss: 0.3257, Val Loss: nan
Epoch [6/30] - Train Loss: 0.3146, Val Loss: nan
Epoch [7/30] - Train Loss: 0.3061, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2990, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2929, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2875, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2828, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2786, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2750, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2714, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2687, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2664, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2638, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2621, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2600, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2587, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2572, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2556, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2542, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2532, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2521, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2512, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2500, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2494, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2488, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2479, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.0001, nn__num_layers=1; total time=16.8min
Model with 1 hidden layers and hidden_size 16 has 5049 trainable parameters.
Epoch [1/30] - Train Loss: 0.7035, Val Loss: nan
Epoch [2/30] - Train Loss: 0.4156, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3669, Val Loss: nan
Epoch [4/30] - Train Loss: 0.3419, Val Loss: nan
Epoch [5/30] - Train Loss: 0.3259, Val Loss: nan
Epoch [6/30] - Train Loss: 0.3148, Val Loss: nan
Epoch [7/30] - Train Loss: 0.3070, Val Loss: nan
Epoch [8/30] - Train Loss: 0.3008, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2958, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2914, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2877, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2843, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2814, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2787, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2765, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2741, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2721, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2702, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2687, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2667, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2654, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2639, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2626, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2613, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2601, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2591, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2583, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2572, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2562, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2556, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.0001, nn__num_layers=1; total time=16.9min
Model with 1 hidden layers and hidden_size 16 has 5049 trainable parameters.
Epoch [1/30] - Train Loss: 0.6931, Val Loss: nan
Epoch [2/30] - Train Loss: 0.4037, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3589, Val Loss: nan
Epoch [4/30] - Train Loss: 0.3354, Val Loss: nan
Epoch [5/30] - Train Loss: 0.3200, Val Loss: nan
Epoch [6/30] - Train Loss: 0.3090, Val Loss: nan
Epoch [7/30] - Train Loss: 0.3008, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2944, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2891, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2847, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2809, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2775, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2748, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2721, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2696, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2679, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2659, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2641, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2628, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2612, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2602, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2590, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2575, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2565, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2555, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2545, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2539, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2529, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2521, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2513, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.0001, nn__num_layers=1; total time=16.7min
Model with 2 hidden layers and hidden_size 16 has 5321 trainable parameters.
Epoch [1/30] - Train Loss: 0.7247, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3989, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3490, Val Loss: nan
Epoch [4/30] - Train Loss: 0.3212, Val Loss: nan
Epoch [5/30] - Train Loss: 0.3028, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2890, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2784, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2701, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2633, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2576, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2530, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2489, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2451, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2422, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2397, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2373, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2348, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2330, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2312, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2297, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2280, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2267, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2256, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2243, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2233, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2222, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2211, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2203, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2194, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2186, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.0001, nn__num_layers=2; total time=18.5min
Model with 2 hidden layers and hidden_size 16 has 5321 trainable parameters.
Epoch [1/30] - Train Loss: 0.7064, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3873, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3426, Val Loss: nan
Epoch [4/30] - Train Loss: 0.3180, Val Loss: nan
Epoch [5/30] - Train Loss: 0.3006, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2870, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2768, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2689, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2630, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2578, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2538, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2501, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2471, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2441, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2418, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2397, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2376, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2357, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2341, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2327, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2314, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2304, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2291, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2280, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2273, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2262, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2253, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2248, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2240, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2233, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.0001, nn__num_layers=2; total time=18.6min
Model with 2 hidden layers and hidden_size 16 has 5321 trainable parameters.
Epoch [1/30] - Train Loss: 0.7138, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3944, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3441, Val Loss: nan
Epoch [4/30] - Train Loss: 0.3195, Val Loss: nan
Epoch [5/30] - Train Loss: 0.3031, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2910, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2815, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2736, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2672, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2620, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2576, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2540, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2508, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2482, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2458, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2437, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2416, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2397, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2382, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2367, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2352, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2338, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2327, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2314, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2302, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2293, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2280, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2270, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2262, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2252, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.0001, nn__num_layers=2; total time=18.4min
Model with 3 hidden layers and hidden_size 16 has 5593 trainable parameters.
Epoch [1/30] - Train Loss: 0.7379, Val Loss: nan
Epoch [2/30] - Train Loss: 0.4023, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3480, Val Loss: nan
Epoch [4/30] - Train Loss: 0.3181, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2980, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2839, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2735, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2657, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2592, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2542, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2496, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2457, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2421, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2390, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2364, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2340, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2316, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2296, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2279, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2260, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2244, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2232, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2215, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2206, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2194, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2182, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2173, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2163, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2155, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2145, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.0001, nn__num_layers=3; total time=20.2min
Model with 3 hidden layers and hidden_size 16 has 5593 trainable parameters.
Epoch [1/30] - Train Loss: 0.7125, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3924, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3420, Val Loss: nan
Epoch [4/30] - Train Loss: 0.3141, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2961, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2832, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2732, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2658, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2588, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2539, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2492, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2454, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2419, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2391, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2363, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2340, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2318, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2297, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2278, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2262, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2246, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2230, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2217, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2204, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2193, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2180, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2171, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2160, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2152, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2144, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.0001, nn__num_layers=3; total time=19.9min
Model with 3 hidden layers and hidden_size 16 has 5593 trainable parameters.
Epoch [1/30] - Train Loss: 0.7272, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3907, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3359, Val Loss: nan
Epoch [4/30] - Train Loss: 0.3081, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2905, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2776, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2678, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2606, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2548, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2501, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2460, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2428, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2403, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2376, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2356, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2339, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2321, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2305, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2292, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2277, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2263, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2252, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2240, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2230, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2220, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2214, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2204, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2194, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2185, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2179, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.0001, nn__num_layers=3; total time=19.6min
Model with 1 hidden layers and hidden_size 32 has 10089 trainable parameters.
Epoch [1/30] - Train Loss: 0.3647, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2802, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2631, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2524, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2450, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2403, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2367, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2342, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2309, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2289, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2275, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2262, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2245, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2237, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2221, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2211, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2210, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2186, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2190, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2180, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2186, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2168, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2160, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2157, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2154, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2147, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2141, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2134, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2127, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2120, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.001, nn__num_layers=1; total time=16.8min
Model with 1 hidden layers and hidden_size 32 has 10089 trainable parameters.
Epoch [1/30] - Train Loss: 0.3654, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2802, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2619, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2529, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2456, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2410, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2365, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2346, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2318, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2288, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2278, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2254, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2251, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2234, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2224, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2210, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2206, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2194, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2185, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2171, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2178, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2171, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2149, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2148, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2145, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2145, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2131, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2135, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2123, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2128, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.001, nn__num_layers=1; total time=16.9min
Model with 1 hidden layers and hidden_size 32 has 10089 trainable parameters.
Epoch [1/30] - Train Loss: 0.3643, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2764, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2602, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2497, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2440, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2396, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2346, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2327, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2298, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2277, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2258, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2234, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2233, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2212, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2201, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2192, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2176, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2174, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2157, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2164, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2140, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2136, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2131, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2132, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2118, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2116, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2106, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2109, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2097, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2090, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.001, nn__num_layers=1; total time=17.0min
Model with 2 hidden layers and hidden_size 32 has 11145 trainable parameters.
Epoch [1/30] - Train Loss: 0.3298, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2398, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2220, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2118, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2044, Val Loss: nan
Epoch [6/30] - Train Loss: 0.1998, Val Loss: nan
Epoch [7/30] - Train Loss: 0.1960, Val Loss: nan
Epoch [8/30] - Train Loss: 0.1925, Val Loss: nan
Epoch [9/30] - Train Loss: 0.1907, Val Loss: nan
Epoch [10/30] - Train Loss: 0.1880, Val Loss: nan
Epoch [11/30] - Train Loss: 0.1863, Val Loss: nan
Epoch [12/30] - Train Loss: 0.1848, Val Loss: nan
Epoch [13/30] - Train Loss: 0.1829, Val Loss: nan
Epoch [14/30] - Train Loss: 0.1816, Val Loss: nan
Epoch [15/30] - Train Loss: 0.1805, Val Loss: nan
Epoch [16/30] - Train Loss: 0.1798, Val Loss: nan
Epoch [17/30] - Train Loss: 0.1791, Val Loss: nan
Epoch [18/30] - Train Loss: 0.1787, Val Loss: nan
Epoch [19/30] - Train Loss: 0.1772, Val Loss: nan
Epoch [20/30] - Train Loss: 0.1766, Val Loss: nan
Epoch [21/30] - Train Loss: 0.1766, Val Loss: nan
Epoch [22/30] - Train Loss: 0.1765, Val Loss: nan
Epoch [23/30] - Train Loss: 0.1758, Val Loss: nan
Epoch [24/30] - Train Loss: 0.1755, Val Loss: nan
Epoch [25/30] - Train Loss: 0.1749, Val Loss: nan
Epoch [26/30] - Train Loss: 0.1732, Val Loss: nan
Epoch [27/30] - Train Loss: 0.1733, Val Loss: nan
Epoch [28/30] - Train Loss: 0.1725, Val Loss: nan
Epoch [29/30] - Train Loss: 0.1726, Val Loss: nan
Epoch [30/30] - Train Loss: 0.1722, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.001, nn__num_layers=2; total time=18.6min
Model with 2 hidden layers and hidden_size 32 has 11145 trainable parameters.
Epoch [1/30] - Train Loss: 0.3400, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2469, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2259, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2143, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2081, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2031, Val Loss: nan
Epoch [7/30] - Train Loss: 0.1991, Val Loss: nan
Epoch [8/30] - Train Loss: 0.1962, Val Loss: nan
Epoch [9/30] - Train Loss: 0.1938, Val Loss: nan
Epoch [10/30] - Train Loss: 0.1916, Val Loss: nan
Epoch [11/30] - Train Loss: 0.1899, Val Loss: nan
Epoch [12/30] - Train Loss: 0.1881, Val Loss: nan
Epoch [13/30] - Train Loss: 0.1875, Val Loss: nan
Epoch [14/30] - Train Loss: 0.1858, Val Loss: nan
Epoch [15/30] - Train Loss: 0.1846, Val Loss: nan
Epoch [16/30] - Train Loss: 0.1842, Val Loss: nan
Epoch [17/30] - Train Loss: 0.1831, Val Loss: nan
Epoch [18/30] - Train Loss: 0.1820, Val Loss: nan
Epoch [19/30] - Train Loss: 0.1813, Val Loss: nan
Epoch [20/30] - Train Loss: 0.1808, Val Loss: nan
Epoch [21/30] - Train Loss: 0.1800, Val Loss: nan
Epoch [22/30] - Train Loss: 0.1791, Val Loss: nan
Epoch [23/30] - Train Loss: 0.1791, Val Loss: nan
Epoch [24/30] - Train Loss: 0.1789, Val Loss: nan
Epoch [25/30] - Train Loss: 0.1787, Val Loss: nan
Epoch [26/30] - Train Loss: 0.1771, Val Loss: nan
Epoch [27/30] - Train Loss: 0.1771, Val Loss: nan
Epoch [28/30] - Train Loss: 0.1769, Val Loss: nan
Epoch [29/30] - Train Loss: 0.1764, Val Loss: nan
Epoch [30/30] - Train Loss: 0.1760, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.001, nn__num_layers=2; total time=18.2min
Model with 2 hidden layers and hidden_size 32 has 11145 trainable parameters.
Epoch [1/30] - Train Loss: 0.3343, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2451, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2237, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2122, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2050, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2000, Val Loss: nan
Epoch [7/30] - Train Loss: 0.1959, Val Loss: nan
Epoch [8/30] - Train Loss: 0.1933, Val Loss: nan
Epoch [9/30] - Train Loss: 0.1905, Val Loss: nan
Epoch [10/30] - Train Loss: 0.1884, Val Loss: nan
Epoch [11/30] - Train Loss: 0.1871, Val Loss: nan
Epoch [12/30] - Train Loss: 0.1853, Val Loss: nan
Epoch [13/30] - Train Loss: 0.1838, Val Loss: nan
Epoch [14/30] - Train Loss: 0.1825, Val Loss: nan
Epoch [15/30] - Train Loss: 0.1814, Val Loss: nan
Epoch [16/30] - Train Loss: 0.1806, Val Loss: nan
Epoch [17/30] - Train Loss: 0.1800, Val Loss: nan
Epoch [18/30] - Train Loss: 0.1794, Val Loss: nan
Epoch [19/30] - Train Loss: 0.1784, Val Loss: nan
Epoch [20/30] - Train Loss: 0.1773, Val Loss: nan
Epoch [21/30] - Train Loss: 0.1764, Val Loss: nan
Epoch [22/30] - Train Loss: 0.1763, Val Loss: nan
Epoch [23/30] - Train Loss: 0.1766, Val Loss: nan
Epoch [24/30] - Train Loss: 0.1757, Val Loss: nan
Epoch [25/30] - Train Loss: 0.1750, Val Loss: nan
Epoch [26/30] - Train Loss: 0.1745, Val Loss: nan
Epoch [27/30] - Train Loss: 0.1745, Val Loss: nan
Epoch [28/30] - Train Loss: 0.1742, Val Loss: nan
Epoch [29/30] - Train Loss: 0.1735, Val Loss: nan
Epoch [30/30] - Train Loss: 0.1729, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.001, nn__num_layers=2; total time=18.4min
Model with 3 hidden layers and hidden_size 32 has 12201 trainable parameters.
Epoch [1/30] - Train Loss: 0.3342, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2409, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2222, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2114, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2051, Val Loss: nan
Epoch [6/30] - Train Loss: 0.1997, Val Loss: nan
Epoch [7/30] - Train Loss: 0.1964, Val Loss: nan
Epoch [8/30] - Train Loss: 0.1921, Val Loss: nan
Epoch [9/30] - Train Loss: 0.1898, Val Loss: nan
Epoch [10/30] - Train Loss: 0.1877, Val Loss: nan
Epoch [11/30] - Train Loss: 0.1867, Val Loss: nan
Epoch [12/30] - Train Loss: 0.1846, Val Loss: nan
Epoch [13/30] - Train Loss: 0.1840, Val Loss: nan
Epoch [14/30] - Train Loss: 0.1821, Val Loss: nan
Epoch [15/30] - Train Loss: 0.1817, Val Loss: nan
Epoch [16/30] - Train Loss: 0.1803, Val Loss: nan
Epoch [17/30] - Train Loss: 0.1795, Val Loss: nan
Epoch [18/30] - Train Loss: 0.1790, Val Loss: nan
Epoch [19/30] - Train Loss: 0.1789, Val Loss: nan
Epoch [20/30] - Train Loss: 0.1777, Val Loss: nan
Epoch [21/30] - Train Loss: 0.1771, Val Loss: nan
Epoch [22/30] - Train Loss: 0.1769, Val Loss: nan
Epoch [23/30] - Train Loss: 0.1767, Val Loss: nan
Epoch [24/30] - Train Loss: 0.1756, Val Loss: nan
Epoch [25/30] - Train Loss: 0.1756, Val Loss: nan
Epoch [26/30] - Train Loss: 0.1741, Val Loss: nan
Epoch [27/30] - Train Loss: 0.1740, Val Loss: nan
Epoch [28/30] - Train Loss: 0.1750, Val Loss: nan
Epoch [29/30] - Train Loss: 0.1739, Val Loss: nan
Epoch [30/30] - Train Loss: 0.1742, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.001, nn__num_layers=3; total time=20.3min
Model with 3 hidden layers and hidden_size 32 has 12201 trainable parameters.
Epoch [1/30] - Train Loss: 0.3318, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2392, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2207, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2122, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2060, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2016, Val Loss: nan
Epoch [7/30] - Train Loss: 0.1972, Val Loss: nan
Epoch [8/30] - Train Loss: 0.1951, Val Loss: nan
Epoch [9/30] - Train Loss: 0.1919, Val Loss: nan
Epoch [10/30] - Train Loss: 0.1893, Val Loss: nan
Epoch [11/30] - Train Loss: 0.1876, Val Loss: nan
Epoch [12/30] - Train Loss: 0.1860, Val Loss: nan
Epoch [13/30] - Train Loss: 0.1850, Val Loss: nan
Epoch [14/30] - Train Loss: 0.1840, Val Loss: nan
Epoch [15/30] - Train Loss: 0.1831, Val Loss: nan
Epoch [16/30] - Train Loss: 0.1819, Val Loss: nan
Epoch [17/30] - Train Loss: 0.1812, Val Loss: nan
Epoch [18/30] - Train Loss: 0.1804, Val Loss: nan
Epoch [19/30] - Train Loss: 0.1795, Val Loss: nan
Epoch [20/30] - Train Loss: 0.1788, Val Loss: nan
Epoch [21/30] - Train Loss: 0.1785, Val Loss: nan
Epoch [22/30] - Train Loss: 0.1785, Val Loss: nan
Epoch [23/30] - Train Loss: 0.1784, Val Loss: nan
Epoch [24/30] - Train Loss: 0.1786, Val Loss: nan
Epoch [25/30] - Train Loss: 0.1789, Val Loss: nan
Epoch [26/30] - Train Loss: 0.1776, Val Loss: nan
Epoch [27/30] - Train Loss: 0.1779, Val Loss: nan
Epoch [28/30] - Train Loss: 0.1792, Val Loss: nan
Epoch [29/30] - Train Loss: 0.1780, Val Loss: nan
Epoch [30/30] - Train Loss: 0.1775, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.001, nn__num_layers=3; total time=20.3min
Model with 3 hidden layers and hidden_size 32 has 12201 trainable parameters.
Epoch [1/30] - Train Loss: 0.3347, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2418, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2228, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2129, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2058, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2009, Val Loss: nan
Epoch [7/30] - Train Loss: 0.1969, Val Loss: nan
Epoch [8/30] - Train Loss: 0.1935, Val Loss: nan
Epoch [9/30] - Train Loss: 0.1913, Val Loss: nan
Epoch [10/30] - Train Loss: 0.1887, Val Loss: nan
Epoch [11/30] - Train Loss: 0.1871, Val Loss: nan
Epoch [12/30] - Train Loss: 0.1856, Val Loss: nan
Epoch [13/30] - Train Loss: 0.1842, Val Loss: nan
Epoch [14/30] - Train Loss: 0.1831, Val Loss: nan
Epoch [15/30] - Train Loss: 0.1822, Val Loss: nan
Epoch [16/30] - Train Loss: 0.1816, Val Loss: nan
Epoch [17/30] - Train Loss: 0.1803, Val Loss: nan
Epoch [18/30] - Train Loss: 0.1793, Val Loss: nan
Epoch [19/30] - Train Loss: 0.1788, Val Loss: nan
Epoch [20/30] - Train Loss: 0.1779, Val Loss: nan
Epoch [21/30] - Train Loss: 0.1782, Val Loss: nan
Epoch [22/30] - Train Loss: 0.1773, Val Loss: nan
Epoch [23/30] - Train Loss: 0.1767, Val Loss: nan
Epoch [24/30] - Train Loss: 0.1760, Val Loss: nan
Epoch [25/30] - Train Loss: 0.1757, Val Loss: nan
Epoch [26/30] - Train Loss: 0.1754, Val Loss: nan
Epoch [27/30] - Train Loss: 0.1756, Val Loss: nan
Epoch [28/30] - Train Loss: 0.1762, Val Loss: nan
Epoch [29/30] - Train Loss: 0.1746, Val Loss: nan
Epoch [30/30] - Train Loss: 0.1745, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.001, nn__num_layers=3; total time=20.1min
Model with 1 hidden layers and hidden_size 32 has 10089 trainable parameters.
Epoch [1/30] - Train Loss: 0.6071, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3554, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3120, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2885, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2730, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2622, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2542, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2477, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2424, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2379, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2343, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2310, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2279, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2256, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2233, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2215, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2196, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2179, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2167, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2154, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2138, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2129, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2118, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2106, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2097, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2087, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2079, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2072, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2064, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2056, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.0001, nn__num_layers=1; total time=17.2min
Model with 1 hidden layers and hidden_size 32 has 10089 trainable parameters.
Epoch [1/30] - Train Loss: 0.5986, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3565, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3141, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2916, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2766, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2661, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2579, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2515, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2459, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2417, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2378, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2348, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2323, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2297, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2275, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2258, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2238, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2225, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2211, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2196, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2184, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2174, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2160, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2155, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2144, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2134, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2128, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2121, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2111, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2103, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.0001, nn__num_layers=1; total time=16.8min
Model with 1 hidden layers and hidden_size 32 has 10089 trainable parameters.
Epoch [1/30] - Train Loss: 0.5914, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3520, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3107, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2881, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2734, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2628, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2548, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2482, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2433, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2390, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2356, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2327, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2299, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2276, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2256, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2237, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2222, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2205, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2191, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2180, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2168, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2158, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2146, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2135, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2123, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2115, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2106, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2101, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2092, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2086, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.0001, nn__num_layers=1; total time=16.8min
Model with 2 hidden layers and hidden_size 32 has 11145 trainable parameters.
Epoch [1/30] - Train Loss: 0.5680, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3187, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2770, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2543, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2399, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2297, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2221, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2158, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2107, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2066, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2026, Val Loss: nan
Epoch [12/30] - Train Loss: 0.1996, Val Loss: nan
Epoch [13/30] - Train Loss: 0.1963, Val Loss: nan
Epoch [14/30] - Train Loss: 0.1938, Val Loss: nan
Epoch [15/30] - Train Loss: 0.1916, Val Loss: nan
Epoch [16/30] - Train Loss: 0.1895, Val Loss: nan
Epoch [17/30] - Train Loss: 0.1876, Val Loss: nan
Epoch [18/30] - Train Loss: 0.1859, Val Loss: nan
Epoch [19/30] - Train Loss: 0.1842, Val Loss: nan
Epoch [20/30] - Train Loss: 0.1829, Val Loss: nan
Epoch [21/30] - Train Loss: 0.1814, Val Loss: nan
Epoch [22/30] - Train Loss: 0.1800, Val Loss: nan
Epoch [23/30] - Train Loss: 0.1790, Val Loss: nan
Epoch [24/30] - Train Loss: 0.1780, Val Loss: nan
Epoch [25/30] - Train Loss: 0.1769, Val Loss: nan
Epoch [26/30] - Train Loss: 0.1758, Val Loss: nan
Epoch [27/30] - Train Loss: 0.1751, Val Loss: nan
Epoch [28/30] - Train Loss: 0.1743, Val Loss: nan
Epoch [29/30] - Train Loss: 0.1734, Val Loss: nan
Epoch [30/30] - Train Loss: 0.1726, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.0001, nn__num_layers=2; total time=18.4min
Model with 2 hidden layers and hidden_size 32 has 11145 trainable parameters.
Epoch [1/30] - Train Loss: 0.5721, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3179, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2754, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2526, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2388, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2290, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2217, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2161, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2112, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2076, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2040, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2012, Val Loss: nan
Epoch [13/30] - Train Loss: 0.1985, Val Loss: nan
Epoch [14/30] - Train Loss: 0.1963, Val Loss: nan
Epoch [15/30] - Train Loss: 0.1943, Val Loss: nan
Epoch [16/30] - Train Loss: 0.1924, Val Loss: nan
Epoch [17/30] - Train Loss: 0.1906, Val Loss: nan
Epoch [18/30] - Train Loss: 0.1890, Val Loss: nan
Epoch [19/30] - Train Loss: 0.1876, Val Loss: nan
Epoch [20/30] - Train Loss: 0.1864, Val Loss: nan
Epoch [21/30] - Train Loss: 0.1850, Val Loss: nan
Epoch [22/30] - Train Loss: 0.1839, Val Loss: nan
Epoch [23/30] - Train Loss: 0.1828, Val Loss: nan
Epoch [24/30] - Train Loss: 0.1818, Val Loss: nan
Epoch [25/30] - Train Loss: 0.1809, Val Loss: nan
Epoch [26/30] - Train Loss: 0.1799, Val Loss: nan
Epoch [27/30] - Train Loss: 0.1786, Val Loss: nan
Epoch [28/30] - Train Loss: 0.1780, Val Loss: nan
Epoch [29/30] - Train Loss: 0.1772, Val Loss: nan
Epoch [30/30] - Train Loss: 0.1763, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.0001, nn__num_layers=2; total time=18.2min
Model with 2 hidden layers and hidden_size 32 has 11145 trainable parameters.
Epoch [1/30] - Train Loss: 0.5504, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3086, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2693, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2487, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2361, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2265, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2192, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2136, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2090, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2047, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2015, Val Loss: nan
Epoch [12/30] - Train Loss: 0.1985, Val Loss: nan
Epoch [13/30] - Train Loss: 0.1958, Val Loss: nan
Epoch [14/30] - Train Loss: 0.1932, Val Loss: nan
Epoch [15/30] - Train Loss: 0.1912, Val Loss: nan
Epoch [16/30] - Train Loss: 0.1892, Val Loss: nan
Epoch [17/30] - Train Loss: 0.1877, Val Loss: nan
Epoch [18/30] - Train Loss: 0.1861, Val Loss: nan
Epoch [19/30] - Train Loss: 0.1844, Val Loss: nan
Epoch [20/30] - Train Loss: 0.1830, Val Loss: nan
Epoch [21/30] - Train Loss: 0.1818, Val Loss: nan
Epoch [22/30] - Train Loss: 0.1807, Val Loss: nan
Epoch [23/30] - Train Loss: 0.1797, Val Loss: nan
Epoch [24/30] - Train Loss: 0.1786, Val Loss: nan
Epoch [25/30] - Train Loss: 0.1775, Val Loss: nan
Epoch [26/30] - Train Loss: 0.1766, Val Loss: nan
Epoch [27/30] - Train Loss: 0.1756, Val Loss: nan
Epoch [28/30] - Train Loss: 0.1749, Val Loss: nan
Epoch [29/30] - Train Loss: 0.1738, Val Loss: nan
Epoch [30/30] - Train Loss: 0.1731, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.0001, nn__num_layers=2; total time=18.2min
Model with 3 hidden layers and hidden_size 32 has 12201 trainable parameters.
Epoch [1/30] - Train Loss: 0.5740, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3195, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2712, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2474, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2326, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2226, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2151, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2089, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2040, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2000, Val Loss: nan
Epoch [11/30] - Train Loss: 0.1964, Val Loss: nan
Epoch [12/30] - Train Loss: 0.1932, Val Loss: nan
Epoch [13/30] - Train Loss: 0.1904, Val Loss: nan
Epoch [14/30] - Train Loss: 0.1878, Val Loss: nan
Epoch [15/30] - Train Loss: 0.1855, Val Loss: nan
Epoch [16/30] - Train Loss: 0.1833, Val Loss: nan
Epoch [17/30] - Train Loss: 0.1817, Val Loss: nan
Epoch [18/30] - Train Loss: 0.1800, Val Loss: nan
Epoch [19/30] - Train Loss: 0.1784, Val Loss: nan
Epoch [20/30] - Train Loss: 0.1770, Val Loss: nan
Epoch [21/30] - Train Loss: 0.1757, Val Loss: nan
Epoch [22/30] - Train Loss: 0.1745, Val Loss: nan
Epoch [23/30] - Train Loss: 0.1732, Val Loss: nan
Epoch [24/30] - Train Loss: 0.1723, Val Loss: nan
Epoch [25/30] - Train Loss: 0.1712, Val Loss: nan
Epoch [26/30] - Train Loss: 0.1701, Val Loss: nan
Epoch [27/30] - Train Loss: 0.1691, Val Loss: nan
Epoch [28/30] - Train Loss: 0.1682, Val Loss: nan
Epoch [29/30] - Train Loss: 0.1673, Val Loss: nan
Epoch [30/30] - Train Loss: 0.1664, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.0001, nn__num_layers=3; total time=19.8min
Model with 3 hidden layers and hidden_size 32 has 12201 trainable parameters.
Epoch [1/30] - Train Loss: 0.5705, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3112, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2689, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2469, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2321, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2228, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2149, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2092, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2042, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2003, Val Loss: nan
Epoch [11/30] - Train Loss: 0.1968, Val Loss: nan
Epoch [12/30] - Train Loss: 0.1940, Val Loss: nan
Epoch [13/30] - Train Loss: 0.1912, Val Loss: nan
Epoch [14/30] - Train Loss: 0.1889, Val Loss: nan
Epoch [15/30] - Train Loss: 0.1866, Val Loss: nan
Epoch [16/30] - Train Loss: 0.1849, Val Loss: nan
Epoch [17/30] - Train Loss: 0.1828, Val Loss: nan
Epoch [18/30] - Train Loss: 0.1813, Val Loss: nan
Epoch [19/30] - Train Loss: 0.1798, Val Loss: nan
Epoch [20/30] - Train Loss: 0.1785, Val Loss: nan
Epoch [21/30] - Train Loss: 0.1771, Val Loss: nan
Epoch [22/30] - Train Loss: 0.1761, Val Loss: nan
Epoch [23/30] - Train Loss: 0.1749, Val Loss: nan
Epoch [24/30] - Train Loss: 0.1740, Val Loss: nan
Epoch [25/30] - Train Loss: 0.1730, Val Loss: nan
Epoch [26/30] - Train Loss: 0.1720, Val Loss: nan
Epoch [27/30] - Train Loss: 0.1712, Val Loss: nan
Epoch [28/30] - Train Loss: 0.1704, Val Loss: nan
Epoch [29/30] - Train Loss: 0.1696, Val Loss: nan
Epoch [30/30] - Train Loss: 0.1689, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.0001, nn__num_layers=3; total time=20.3min
Model with 3 hidden layers and hidden_size 32 has 12201 trainable parameters.
Epoch [1/30] - Train Loss: 0.5733, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3121, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2708, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2479, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2329, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2220, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2140, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2075, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2021, Val Loss: nan
Epoch [10/30] - Train Loss: 0.1981, Val Loss: nan
Epoch [11/30] - Train Loss: 0.1939, Val Loss: nan
Epoch [12/30] - Train Loss: 0.1906, Val Loss: nan
Epoch [13/30] - Train Loss: 0.1880, Val Loss: nan
Epoch [14/30] - Train Loss: 0.1854, Val Loss: nan
Epoch [15/30] - Train Loss: 0.1828, Val Loss: nan
Epoch [16/30] - Train Loss: 0.1811, Val Loss: nan
Epoch [17/30] - Train Loss: 0.1789, Val Loss: nan
Epoch [18/30] - Train Loss: 0.1772, Val Loss: nan
Epoch [19/30] - Train Loss: 0.1759, Val Loss: nan
Epoch [20/30] - Train Loss: 0.1745, Val Loss: nan
Epoch [21/30] - Train Loss: 0.1728, Val Loss: nan
Epoch [22/30] - Train Loss: 0.1716, Val Loss: nan
Epoch [23/30] - Train Loss: 0.1706, Val Loss: nan
Epoch [24/30] - Train Loss: 0.1694, Val Loss: nan
Epoch [25/30] - Train Loss: 0.1684, Val Loss: nan
Epoch [26/30] - Train Loss: 0.1674, Val Loss: nan
Epoch [27/30] - Train Loss: 0.1666, Val Loss: nan
Epoch [28/30] - Train Loss: 0.1659, Val Loss: nan
Epoch [29/30] - Train Loss: 0.1649, Val Loss: nan
Epoch [30/30] - Train Loss: 0.1640, Val Loss: nan
[CV] END nn__batch_size=16, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.0001, nn__num_layers=3; total time=20.1min
Model with 1 hidden layers and hidden_size 16 has 5049 trainable parameters.
Epoch [1/30] - Train Loss: 0.4351, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3239, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3022, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2897, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2820, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2772, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2721, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2692, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2663, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2644, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2624, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2608, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2592, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2577, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2559, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2544, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2535, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2524, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2511, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2499, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2492, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2485, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2475, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2470, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2465, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2455, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2455, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2449, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2443, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2431, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.001, nn__num_layers=1; total time= 9.7min
Model with 1 hidden layers and hidden_size 16 has 5049 trainable parameters.
Epoch [1/30] - Train Loss: 0.4285, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3170, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3008, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2918, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2862, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2815, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2786, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2751, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2732, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2709, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2688, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2683, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2662, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2651, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2634, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2626, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2621, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2605, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2600, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2591, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2582, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2574, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2569, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2557, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2545, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2542, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2536, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2526, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2519, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2510, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.001, nn__num_layers=1; total time= 9.6min
Model with 1 hidden layers and hidden_size 16 has 5049 trainable parameters.
Epoch [1/30] - Train Loss: 0.4230, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3128, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2937, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2838, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2771, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2720, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2685, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2658, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2634, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2619, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2596, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2587, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2569, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2561, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2554, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2543, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2529, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2524, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2516, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2508, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2502, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2491, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2487, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2480, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2478, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2468, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2466, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2463, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2454, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2454, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.001, nn__num_layers=1; total time= 9.5min
Model with 2 hidden layers and hidden_size 16 has 5321 trainable parameters.
Epoch [1/30] - Train Loss: 0.3973, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2808, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2603, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2498, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2443, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2380, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2348, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2324, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2299, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2277, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2258, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2248, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2231, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2214, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2204, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2191, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2177, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2170, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2163, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2152, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2142, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2140, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2132, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2124, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2117, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2116, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2107, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2101, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2097, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2089, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.001, nn__num_layers=2; total time=10.7min
Model with 2 hidden layers and hidden_size 16 has 5321 trainable parameters.
Epoch [1/30] - Train Loss: 0.4095, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2889, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2687, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2571, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2511, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2456, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2421, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2398, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2363, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2333, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2317, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2295, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2273, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2258, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2243, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2239, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2223, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2213, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2207, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2199, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2194, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2184, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2179, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2173, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2165, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2161, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2150, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2151, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2151, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2143, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.001, nn__num_layers=2; total time=10.6min
Model with 2 hidden layers and hidden_size 16 has 5321 trainable parameters.
Epoch [1/30] - Train Loss: 0.4036, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2916, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2709, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2597, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2521, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2469, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2418, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2375, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2349, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2329, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2306, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2290, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2277, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2254, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2242, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2235, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2224, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2209, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2199, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2197, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2183, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2173, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2166, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2162, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2156, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2148, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2151, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2142, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2136, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2132, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.001, nn__num_layers=2; total time=10.6min
Model with 3 hidden layers and hidden_size 16 has 5593 trainable parameters.
Epoch [1/30] - Train Loss: 0.4085, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2834, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2600, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2485, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2408, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2342, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2298, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2254, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2221, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2194, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2176, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2153, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2138, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2122, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2116, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2095, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2086, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2064, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2056, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2046, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2041, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2031, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2027, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2021, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2016, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2007, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2003, Val Loss: nan
Epoch [28/30] - Train Loss: 0.1995, Val Loss: nan
Epoch [29/30] - Train Loss: 0.1992, Val Loss: nan
Epoch [30/30] - Train Loss: 0.1984, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.001, nn__num_layers=3; total time=11.4min
Model with 3 hidden layers and hidden_size 16 has 5593 trainable parameters.
Epoch [1/30] - Train Loss: 0.4154, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2836, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2640, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2538, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2463, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2403, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2347, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2312, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2274, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2243, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2217, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2194, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2174, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2159, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2142, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2129, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2121, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2105, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2094, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2087, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2071, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2064, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2054, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2051, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2046, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2035, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2037, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2028, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2028, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2015, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.001, nn__num_layers=3; total time=11.6min
Model with 3 hidden layers and hidden_size 16 has 5593 trainable parameters.
Epoch [1/30] - Train Loss: 0.4173, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2835, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2622, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2509, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2433, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2379, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2332, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2291, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2265, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2234, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2217, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2201, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2179, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2169, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2163, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2146, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2136, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2125, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2114, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2108, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2098, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2087, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2084, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2074, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2068, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2055, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2050, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2043, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2036, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2030, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.001, nn__num_layers=3; total time=11.4min
Model with 1 hidden layers and hidden_size 16 has 5049 trainable parameters.
Epoch [1/30] - Train Loss: 0.8027, Val Loss: nan
Epoch [2/30] - Train Loss: 0.4625, Val Loss: nan
Epoch [3/30] - Train Loss: 0.4011, Val Loss: nan
Epoch [4/30] - Train Loss: 0.3701, Val Loss: nan
Epoch [5/30] - Train Loss: 0.3498, Val Loss: nan
Epoch [6/30] - Train Loss: 0.3352, Val Loss: nan
Epoch [7/30] - Train Loss: 0.3242, Val Loss: nan
Epoch [8/30] - Train Loss: 0.3153, Val Loss: nan
Epoch [9/30] - Train Loss: 0.3081, Val Loss: nan
Epoch [10/30] - Train Loss: 0.3020, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2968, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2923, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2884, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2850, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2818, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2791, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2769, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2749, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2730, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2712, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2696, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2680, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2667, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2655, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2640, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2630, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2619, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2608, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2598, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2588, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.0001, nn__num_layers=1; total time= 9.6min
Model with 1 hidden layers and hidden_size 16 has 5049 trainable parameters.
Epoch [1/30] - Train Loss: 0.7971, Val Loss: nan
Epoch [2/30] - Train Loss: 0.4545, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3908, Val Loss: nan
Epoch [4/30] - Train Loss: 0.3591, Val Loss: nan
Epoch [5/30] - Train Loss: 0.3386, Val Loss: nan
Epoch [6/30] - Train Loss: 0.3242, Val Loss: nan
Epoch [7/30] - Train Loss: 0.3138, Val Loss: nan
Epoch [8/30] - Train Loss: 0.3056, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2989, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2933, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2886, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2846, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2808, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2774, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2747, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2720, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2696, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2676, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2660, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2644, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2629, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2616, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2604, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2594, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2584, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2574, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2565, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2557, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2548, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2542, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.0001, nn__num_layers=1; total time= 9.7min
Model with 1 hidden layers and hidden_size 16 has 5049 trainable parameters.
Epoch [1/30] - Train Loss: 0.7924, Val Loss: nan
Epoch [2/30] - Train Loss: 0.4431, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3842, Val Loss: nan
Epoch [4/30] - Train Loss: 0.3556, Val Loss: nan
Epoch [5/30] - Train Loss: 0.3376, Val Loss: nan
Epoch [6/30] - Train Loss: 0.3250, Val Loss: nan
Epoch [7/30] - Train Loss: 0.3153, Val Loss: nan
Epoch [8/30] - Train Loss: 0.3076, Val Loss: nan
Epoch [9/30] - Train Loss: 0.3013, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2958, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2913, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2873, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2838, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2807, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2778, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2753, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2731, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2708, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2690, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2671, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2655, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2640, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2625, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2613, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2599, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2588, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2578, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2568, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2559, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2549, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.0001, nn__num_layers=1; total time= 9.7min
Model with 2 hidden layers and hidden_size 16 has 5321 trainable parameters.
Epoch [1/30] - Train Loss: 0.8229, Val Loss: nan
Epoch [2/30] - Train Loss: 0.4384, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3707, Val Loss: nan
Epoch [4/30] - Train Loss: 0.3387, Val Loss: nan
Epoch [5/30] - Train Loss: 0.3194, Val Loss: nan
Epoch [6/30] - Train Loss: 0.3060, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2959, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2876, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2808, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2752, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2705, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2664, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2628, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2597, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2569, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2543, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2518, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2496, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2475, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2456, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2439, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2424, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2408, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2393, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2381, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2370, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2360, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2348, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2337, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2329, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.0001, nn__num_layers=2; total time=10.7min
Model with 2 hidden layers and hidden_size 16 has 5321 trainable parameters.
Epoch [1/30] - Train Loss: 0.8670, Val Loss: nan
Epoch [2/30] - Train Loss: 0.4405, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3749, Val Loss: nan
Epoch [4/30] - Train Loss: 0.3449, Val Loss: nan
Epoch [5/30] - Train Loss: 0.3249, Val Loss: nan
Epoch [6/30] - Train Loss: 0.3101, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2975, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2875, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2794, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2729, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2675, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2632, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2593, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2561, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2531, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2506, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2484, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2464, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2445, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2429, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2413, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2399, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2387, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2376, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2363, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2353, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2343, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2333, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2324, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2315, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.0001, nn__num_layers=2; total time=10.5min
Model with 2 hidden layers and hidden_size 16 has 5321 trainable parameters.
Epoch [1/30] - Train Loss: 0.7985, Val Loss: nan
Epoch [2/30] - Train Loss: 0.4299, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3624, Val Loss: nan
Epoch [4/30] - Train Loss: 0.3298, Val Loss: nan
Epoch [5/30] - Train Loss: 0.3095, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2955, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2851, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2774, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2712, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2660, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2615, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2579, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2543, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2510, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2481, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2454, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2428, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2406, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2385, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2365, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2346, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2330, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2315, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2300, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2286, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2274, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2261, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2249, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2239, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2228, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.0001, nn__num_layers=2; total time=10.6min
Model with 3 hidden layers and hidden_size 16 has 5593 trainable parameters.
Epoch [1/30] - Train Loss: 0.8348, Val Loss: nan
Epoch [2/30] - Train Loss: 0.4309, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3709, Val Loss: nan
Epoch [4/30] - Train Loss: 0.3414, Val Loss: nan
Epoch [5/30] - Train Loss: 0.3219, Val Loss: nan
Epoch [6/30] - Train Loss: 0.3065, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2938, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2834, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2750, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2679, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2622, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2575, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2533, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2495, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2464, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2438, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2412, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2387, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2368, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2348, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2332, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2316, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2301, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2290, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2274, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2263, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2253, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2243, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2233, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2224, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.0001, nn__num_layers=3; total time=11.5min
Model with 3 hidden layers and hidden_size 16 has 5593 trainable parameters.
Epoch [1/30] - Train Loss: 0.8676, Val Loss: nan
Epoch [2/30] - Train Loss: 0.4371, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3728, Val Loss: nan
Epoch [4/30] - Train Loss: 0.3425, Val Loss: nan
Epoch [5/30] - Train Loss: 0.3229, Val Loss: nan
Epoch [6/30] - Train Loss: 0.3086, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2976, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2885, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2810, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2750, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2698, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2653, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2611, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2576, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2545, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2515, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2489, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2466, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2445, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2426, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2407, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2387, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2369, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2353, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2339, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2323, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2310, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2298, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2285, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2273, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.0001, nn__num_layers=3; total time=11.6min
Model with 3 hidden layers and hidden_size 16 has 5593 trainable parameters.
Epoch [1/30] - Train Loss: 0.8317, Val Loss: nan
Epoch [2/30] - Train Loss: 0.4304, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3669, Val Loss: nan
Epoch [4/30] - Train Loss: 0.3366, Val Loss: nan
Epoch [5/30] - Train Loss: 0.3157, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2996, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2876, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2784, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2712, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2653, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2602, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2560, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2523, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2489, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2461, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2435, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2413, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2391, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2369, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2350, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2333, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2317, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2301, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2287, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2272, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2261, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2251, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2239, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2229, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2219, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=16, nn__learning_rate=0.0001, nn__num_layers=3; total time=11.6min
Model with 1 hidden layers and hidden_size 32 has 10089 trainable parameters.
Epoch [1/30] - Train Loss: 0.3695, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2710, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2528, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2430, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2366, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2322, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2288, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2255, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2234, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2199, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2186, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2164, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2159, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2142, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2121, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2111, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2091, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2088, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2077, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2071, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2063, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2056, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2049, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2037, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2041, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2028, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2025, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2021, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2016, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2013, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.001, nn__num_layers=1; total time= 9.8min
Model with 1 hidden layers and hidden_size 32 has 10089 trainable parameters.
Epoch [1/30] - Train Loss: 0.3791, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2785, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2595, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2503, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2428, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2382, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2339, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2309, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2279, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2249, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2228, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2214, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2189, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2191, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2168, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2153, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2141, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2132, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2125, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2109, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2100, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2091, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2086, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2082, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2072, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2069, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2059, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2055, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2051, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2040, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.001, nn__num_layers=1; total time= 9.6min
Model with 1 hidden layers and hidden_size 32 has 10089 trainable parameters.
Epoch [1/30] - Train Loss: 0.3792, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2755, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2555, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2447, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2365, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2322, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2286, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2254, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2229, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2205, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2181, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2169, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2153, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2134, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2126, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2117, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2111, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2093, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2088, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2076, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2070, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2065, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2056, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2059, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2051, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2047, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2036, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2031, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2025, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2031, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.001, nn__num_layers=1; total time= 9.7min
Model with 2 hidden layers and hidden_size 32 has 11145 trainable parameters.
Epoch [1/30] - Train Loss: 0.3436, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2419, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2233, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2127, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2054, Val Loss: nan
Epoch [6/30] - Train Loss: 0.1994, Val Loss: nan
Epoch [7/30] - Train Loss: 0.1957, Val Loss: nan
Epoch [8/30] - Train Loss: 0.1915, Val Loss: nan
Epoch [9/30] - Train Loss: 0.1893, Val Loss: nan
Epoch [10/30] - Train Loss: 0.1863, Val Loss: nan
Epoch [11/30] - Train Loss: 0.1848, Val Loss: nan
Epoch [12/30] - Train Loss: 0.1831, Val Loss: nan
Epoch [13/30] - Train Loss: 0.1815, Val Loss: nan
Epoch [14/30] - Train Loss: 0.1797, Val Loss: nan
Epoch [15/30] - Train Loss: 0.1781, Val Loss: nan
Epoch [16/30] - Train Loss: 0.1762, Val Loss: nan
Epoch [17/30] - Train Loss: 0.1745, Val Loss: nan
Epoch [18/30] - Train Loss: 0.1739, Val Loss: nan
Epoch [19/30] - Train Loss: 0.1723, Val Loss: nan
Epoch [20/30] - Train Loss: 0.1719, Val Loss: nan
Epoch [21/30] - Train Loss: 0.1704, Val Loss: nan
Epoch [22/30] - Train Loss: 0.1699, Val Loss: nan
Epoch [23/30] - Train Loss: 0.1695, Val Loss: nan
Epoch [24/30] - Train Loss: 0.1687, Val Loss: nan
Epoch [25/30] - Train Loss: 0.1684, Val Loss: nan
Epoch [26/30] - Train Loss: 0.1676, Val Loss: nan
Epoch [27/30] - Train Loss: 0.1667, Val Loss: nan
Epoch [28/30] - Train Loss: 0.1668, Val Loss: nan
Epoch [29/30] - Train Loss: 0.1664, Val Loss: nan
Epoch [30/30] - Train Loss: 0.1662, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.001, nn__num_layers=2; total time=10.6min
Model with 2 hidden layers and hidden_size 32 has 11145 trainable parameters.
Epoch [1/30] - Train Loss: 0.3549, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2469, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2259, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2143, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2074, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2014, Val Loss: nan
Epoch [7/30] - Train Loss: 0.1970, Val Loss: nan
Epoch [8/30] - Train Loss: 0.1940, Val Loss: nan
Epoch [9/30] - Train Loss: 0.1906, Val Loss: nan
Epoch [10/30] - Train Loss: 0.1880, Val Loss: nan
Epoch [11/30] - Train Loss: 0.1862, Val Loss: nan
Epoch [12/30] - Train Loss: 0.1841, Val Loss: nan
Epoch [13/30] - Train Loss: 0.1825, Val Loss: nan
Epoch [14/30] - Train Loss: 0.1810, Val Loss: nan
Epoch [15/30] - Train Loss: 0.1796, Val Loss: nan
Epoch [16/30] - Train Loss: 0.1785, Val Loss: nan
Epoch [17/30] - Train Loss: 0.1779, Val Loss: nan
Epoch [18/30] - Train Loss: 0.1769, Val Loss: nan
Epoch [19/30] - Train Loss: 0.1764, Val Loss: nan
Epoch [20/30] - Train Loss: 0.1750, Val Loss: nan
Epoch [21/30] - Train Loss: 0.1745, Val Loss: nan
Epoch [22/30] - Train Loss: 0.1734, Val Loss: nan
Epoch [23/30] - Train Loss: 0.1730, Val Loss: nan
Epoch [24/30] - Train Loss: 0.1723, Val Loss: nan
Epoch [25/30] - Train Loss: 0.1721, Val Loss: nan
Epoch [26/30] - Train Loss: 0.1708, Val Loss: nan
Epoch [27/30] - Train Loss: 0.1701, Val Loss: nan
Epoch [28/30] - Train Loss: 0.1699, Val Loss: nan
Epoch [29/30] - Train Loss: 0.1694, Val Loss: nan
Epoch [30/30] - Train Loss: 0.1687, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.001, nn__num_layers=2; total time=10.5min
Model with 2 hidden layers and hidden_size 32 has 11145 trainable parameters.
Epoch [1/30] - Train Loss: 0.3496, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2465, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2254, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2142, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2064, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2014, Val Loss: nan
Epoch [7/30] - Train Loss: 0.1967, Val Loss: nan
Epoch [8/30] - Train Loss: 0.1933, Val Loss: nan
Epoch [9/30] - Train Loss: 0.1894, Val Loss: nan
Epoch [10/30] - Train Loss: 0.1878, Val Loss: nan
Epoch [11/30] - Train Loss: 0.1854, Val Loss: nan
Epoch [12/30] - Train Loss: 0.1839, Val Loss: nan
Epoch [13/30] - Train Loss: 0.1819, Val Loss: nan
Epoch [14/30] - Train Loss: 0.1802, Val Loss: nan
Epoch [15/30] - Train Loss: 0.1790, Val Loss: nan
Epoch [16/30] - Train Loss: 0.1774, Val Loss: nan
Epoch [17/30] - Train Loss: 0.1760, Val Loss: nan
Epoch [18/30] - Train Loss: 0.1755, Val Loss: nan
Epoch [19/30] - Train Loss: 0.1741, Val Loss: nan
Epoch [20/30] - Train Loss: 0.1733, Val Loss: nan
Epoch [21/30] - Train Loss: 0.1726, Val Loss: nan
Epoch [22/30] - Train Loss: 0.1714, Val Loss: nan
Epoch [23/30] - Train Loss: 0.1709, Val Loss: nan
Epoch [24/30] - Train Loss: 0.1706, Val Loss: nan
Epoch [25/30] - Train Loss: 0.1699, Val Loss: nan
Epoch [26/30] - Train Loss: 0.1689, Val Loss: nan
Epoch [27/30] - Train Loss: 0.1685, Val Loss: nan
Epoch [28/30] - Train Loss: 0.1681, Val Loss: nan
Epoch [29/30] - Train Loss: 0.1673, Val Loss: nan
Epoch [30/30] - Train Loss: 0.1669, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.001, nn__num_layers=2; total time=10.5min
Model with 3 hidden layers and hidden_size 32 has 12201 trainable parameters.
Epoch [1/30] - Train Loss: 0.3463, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2377, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2173, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2068, Val Loss: nan
Epoch [5/30] - Train Loss: 0.1996, Val Loss: nan
Epoch [6/30] - Train Loss: 0.1944, Val Loss: nan
Epoch [7/30] - Train Loss: 0.1905, Val Loss: nan
Epoch [8/30] - Train Loss: 0.1873, Val Loss: nan
Epoch [9/30] - Train Loss: 0.1840, Val Loss: nan
Epoch [10/30] - Train Loss: 0.1815, Val Loss: nan
Epoch [11/30] - Train Loss: 0.1795, Val Loss: nan
Epoch [12/30] - Train Loss: 0.1779, Val Loss: nan
Epoch [13/30] - Train Loss: 0.1767, Val Loss: nan
Epoch [14/30] - Train Loss: 0.1748, Val Loss: nan
Epoch [15/30] - Train Loss: 0.1733, Val Loss: nan
Epoch [16/30] - Train Loss: 0.1722, Val Loss: nan
Epoch [17/30] - Train Loss: 0.1708, Val Loss: nan
Epoch [18/30] - Train Loss: 0.1702, Val Loss: nan
Epoch [19/30] - Train Loss: 0.1685, Val Loss: nan
Epoch [20/30] - Train Loss: 0.1680, Val Loss: nan
Epoch [21/30] - Train Loss: 0.1672, Val Loss: nan
Epoch [22/30] - Train Loss: 0.1667, Val Loss: nan
Epoch [23/30] - Train Loss: 0.1656, Val Loss: nan
Epoch [24/30] - Train Loss: 0.1649, Val Loss: nan
Epoch [25/30] - Train Loss: 0.1647, Val Loss: nan
Epoch [26/30] - Train Loss: 0.1643, Val Loss: nan
Epoch [27/30] - Train Loss: 0.1640, Val Loss: nan
Epoch [28/30] - Train Loss: 0.1629, Val Loss: nan
Epoch [29/30] - Train Loss: 0.1630, Val Loss: nan
Epoch [30/30] - Train Loss: 0.1626, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.001, nn__num_layers=3; total time=11.6min
Model with 3 hidden layers and hidden_size 32 has 12201 trainable parameters.
Epoch [1/30] - Train Loss: 0.3409, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2375, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2189, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2076, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2005, Val Loss: nan
Epoch [6/30] - Train Loss: 0.1955, Val Loss: nan
Epoch [7/30] - Train Loss: 0.1912, Val Loss: nan
Epoch [8/30] - Train Loss: 0.1884, Val Loss: nan
Epoch [9/30] - Train Loss: 0.1859, Val Loss: nan
Epoch [10/30] - Train Loss: 0.1831, Val Loss: nan
Epoch [11/30] - Train Loss: 0.1815, Val Loss: nan
Epoch [12/30] - Train Loss: 0.1796, Val Loss: nan
Epoch [13/30] - Train Loss: 0.1782, Val Loss: nan
Epoch [14/30] - Train Loss: 0.1768, Val Loss: nan
Epoch [15/30] - Train Loss: 0.1750, Val Loss: nan
Epoch [16/30] - Train Loss: 0.1741, Val Loss: nan
Epoch [17/30] - Train Loss: 0.1725, Val Loss: nan
Epoch [18/30] - Train Loss: 0.1718, Val Loss: nan
Epoch [19/30] - Train Loss: 0.1710, Val Loss: nan
Epoch [20/30] - Train Loss: 0.1698, Val Loss: nan
Epoch [21/30] - Train Loss: 0.1691, Val Loss: nan
Epoch [22/30] - Train Loss: 0.1684, Val Loss: nan
Epoch [23/30] - Train Loss: 0.1679, Val Loss: nan
Epoch [24/30] - Train Loss: 0.1672, Val Loss: nan
Epoch [25/30] - Train Loss: 0.1667, Val Loss: nan
Epoch [26/30] - Train Loss: 0.1663, Val Loss: nan
Epoch [27/30] - Train Loss: 0.1652, Val Loss: nan
Epoch [28/30] - Train Loss: 0.1645, Val Loss: nan
Epoch [29/30] - Train Loss: 0.1644, Val Loss: nan
Epoch [30/30] - Train Loss: 0.1639, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.001, nn__num_layers=3; total time=11.6min
Model with 3 hidden layers and hidden_size 32 has 12201 trainable parameters.
Epoch [1/30] - Train Loss: 0.3379, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2386, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2185, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2072, Val Loss: nan
Epoch [5/30] - Train Loss: 0.1997, Val Loss: nan
Epoch [6/30] - Train Loss: 0.1944, Val Loss: nan
Epoch [7/30] - Train Loss: 0.1903, Val Loss: nan
Epoch [8/30] - Train Loss: 0.1859, Val Loss: nan
Epoch [9/30] - Train Loss: 0.1835, Val Loss: nan
Epoch [10/30] - Train Loss: 0.1813, Val Loss: nan
Epoch [11/30] - Train Loss: 0.1785, Val Loss: nan
Epoch [12/30] - Train Loss: 0.1766, Val Loss: nan
Epoch [13/30] - Train Loss: 0.1752, Val Loss: nan
Epoch [14/30] - Train Loss: 0.1745, Val Loss: nan
Epoch [15/30] - Train Loss: 0.1729, Val Loss: nan
Epoch [16/30] - Train Loss: 0.1719, Val Loss: nan
Epoch [17/30] - Train Loss: 0.1709, Val Loss: nan
Epoch [18/30] - Train Loss: 0.1702, Val Loss: nan
Epoch [19/30] - Train Loss: 0.1689, Val Loss: nan
Epoch [20/30] - Train Loss: 0.1690, Val Loss: nan
Epoch [21/30] - Train Loss: 0.1673, Val Loss: nan
Epoch [22/30] - Train Loss: 0.1672, Val Loss: nan
Epoch [23/30] - Train Loss: 0.1658, Val Loss: nan
Epoch [24/30] - Train Loss: 0.1659, Val Loss: nan
Epoch [25/30] - Train Loss: 0.1652, Val Loss: nan
Epoch [26/30] - Train Loss: 0.1647, Val Loss: nan
Epoch [27/30] - Train Loss: 0.1646, Val Loss: nan
Epoch [28/30] - Train Loss: 0.1641, Val Loss: nan
Epoch [29/30] - Train Loss: 0.1635, Val Loss: nan
Epoch [30/30] - Train Loss: 0.1630, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.001, nn__num_layers=3; total time=11.6min
Model with 1 hidden layers and hidden_size 32 has 10089 trainable parameters.
Epoch [1/30] - Train Loss: 0.6989, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3905, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3380, Val Loss: nan
Epoch [4/30] - Train Loss: 0.3104, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2915, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2781, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2677, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2592, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2522, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2469, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2420, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2382, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2344, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2314, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2290, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2263, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2240, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2220, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2203, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2186, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2171, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2158, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2144, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2133, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2121, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2113, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2101, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2094, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2083, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2078, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.0001, nn__num_layers=1; total time= 9.7min
Model with 1 hidden layers and hidden_size 32 has 10089 trainable parameters.
Epoch [1/30] - Train Loss: 0.6977, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3976, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3468, Val Loss: nan
Epoch [4/30] - Train Loss: 0.3191, Val Loss: nan
Epoch [5/30] - Train Loss: 0.3003, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2860, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2749, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2660, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2584, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2523, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2469, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2422, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2382, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2350, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2322, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2297, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2275, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2255, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2235, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2221, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2206, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2190, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2180, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2166, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2157, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2147, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2136, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2127, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2116, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2111, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.0001, nn__num_layers=1; total time= 9.8min
Model with 1 hidden layers and hidden_size 32 has 10089 trainable parameters.
Epoch [1/30] - Train Loss: 0.6982, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3776, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3273, Val Loss: nan
Epoch [4/30] - Train Loss: 0.3011, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2842, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2719, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2629, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2558, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2498, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2450, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2406, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2372, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2341, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2311, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2289, Val Loss: nan
Epoch [16/30] - Train Loss: 0.2266, Val Loss: nan
Epoch [17/30] - Train Loss: 0.2247, Val Loss: nan
Epoch [18/30] - Train Loss: 0.2226, Val Loss: nan
Epoch [19/30] - Train Loss: 0.2213, Val Loss: nan
Epoch [20/30] - Train Loss: 0.2196, Val Loss: nan
Epoch [21/30] - Train Loss: 0.2183, Val Loss: nan
Epoch [22/30] - Train Loss: 0.2169, Val Loss: nan
Epoch [23/30] - Train Loss: 0.2156, Val Loss: nan
Epoch [24/30] - Train Loss: 0.2148, Val Loss: nan
Epoch [25/30] - Train Loss: 0.2136, Val Loss: nan
Epoch [26/30] - Train Loss: 0.2126, Val Loss: nan
Epoch [27/30] - Train Loss: 0.2115, Val Loss: nan
Epoch [28/30] - Train Loss: 0.2109, Val Loss: nan
Epoch [29/30] - Train Loss: 0.2098, Val Loss: nan
Epoch [30/30] - Train Loss: 0.2091, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.0001, nn__num_layers=1; total time= 9.7min
Model with 2 hidden layers and hidden_size 32 has 11145 trainable parameters.
Epoch [1/30] - Train Loss: 0.6636, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3533, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3032, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2754, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2574, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2452, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2361, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2289, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2229, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2177, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2134, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2098, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2064, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2035, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2008, Val Loss: nan
Epoch [16/30] - Train Loss: 0.1983, Val Loss: nan
Epoch [17/30] - Train Loss: 0.1961, Val Loss: nan
Epoch [18/30] - Train Loss: 0.1941, Val Loss: nan
Epoch [19/30] - Train Loss: 0.1924, Val Loss: nan
Epoch [20/30] - Train Loss: 0.1906, Val Loss: nan
Epoch [21/30] - Train Loss: 0.1891, Val Loss: nan
Epoch [22/30] - Train Loss: 0.1876, Val Loss: nan
Epoch [23/30] - Train Loss: 0.1865, Val Loss: nan
Epoch [24/30] - Train Loss: 0.1849, Val Loss: nan
Epoch [25/30] - Train Loss: 0.1838, Val Loss: nan
Epoch [26/30] - Train Loss: 0.1828, Val Loss: nan
Epoch [27/30] - Train Loss: 0.1817, Val Loss: nan
Epoch [28/30] - Train Loss: 0.1807, Val Loss: nan
Epoch [29/30] - Train Loss: 0.1798, Val Loss: nan
Epoch [30/30] - Train Loss: 0.1789, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.0001, nn__num_layers=2; total time=10.7min
Model with 2 hidden layers and hidden_size 32 has 11145 trainable parameters.
Epoch [1/30] - Train Loss: 0.6577, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3513, Val Loss: nan
Epoch [3/30] - Train Loss: 0.3011, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2744, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2566, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2439, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2344, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2273, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2211, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2163, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2123, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2087, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2054, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2028, Val Loss: nan
Epoch [15/30] - Train Loss: 0.2002, Val Loss: nan
Epoch [16/30] - Train Loss: 0.1981, Val Loss: nan
Epoch [17/30] - Train Loss: 0.1959, Val Loss: nan
Epoch [18/30] - Train Loss: 0.1941, Val Loss: nan
Epoch [19/30] - Train Loss: 0.1924, Val Loss: nan
Epoch [20/30] - Train Loss: 0.1904, Val Loss: nan
Epoch [21/30] - Train Loss: 0.1891, Val Loss: nan
Epoch [22/30] - Train Loss: 0.1875, Val Loss: nan
Epoch [23/30] - Train Loss: 0.1864, Val Loss: nan
Epoch [24/30] - Train Loss: 0.1850, Val Loss: nan
Epoch [25/30] - Train Loss: 0.1840, Val Loss: nan
Epoch [26/30] - Train Loss: 0.1830, Val Loss: nan
Epoch [27/30] - Train Loss: 0.1820, Val Loss: nan
Epoch [28/30] - Train Loss: 0.1809, Val Loss: nan
Epoch [29/30] - Train Loss: 0.1802, Val Loss: nan
Epoch [30/30] - Train Loss: 0.1792, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.0001, nn__num_layers=2; total time=10.6min
Model with 2 hidden layers and hidden_size 32 has 11145 trainable parameters.
Epoch [1/30] - Train Loss: 0.6462, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3444, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2940, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2668, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2498, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2384, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2297, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2227, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2171, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2127, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2090, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2057, Val Loss: nan
Epoch [13/30] - Train Loss: 0.2028, Val Loss: nan
Epoch [14/30] - Train Loss: 0.2002, Val Loss: nan
Epoch [15/30] - Train Loss: 0.1980, Val Loss: nan
Epoch [16/30] - Train Loss: 0.1959, Val Loss: nan
Epoch [17/30] - Train Loss: 0.1944, Val Loss: nan
Epoch [18/30] - Train Loss: 0.1927, Val Loss: nan
Epoch [19/30] - Train Loss: 0.1913, Val Loss: nan
Epoch [20/30] - Train Loss: 0.1896, Val Loss: nan
Epoch [21/30] - Train Loss: 0.1884, Val Loss: nan
Epoch [22/30] - Train Loss: 0.1871, Val Loss: nan
Epoch [23/30] - Train Loss: 0.1860, Val Loss: nan
Epoch [24/30] - Train Loss: 0.1847, Val Loss: nan
Epoch [25/30] - Train Loss: 0.1840, Val Loss: nan
Epoch [26/30] - Train Loss: 0.1831, Val Loss: nan
Epoch [27/30] - Train Loss: 0.1822, Val Loss: nan
Epoch [28/30] - Train Loss: 0.1813, Val Loss: nan
Epoch [29/30] - Train Loss: 0.1805, Val Loss: nan
Epoch [30/30] - Train Loss: 0.1796, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.0001, nn__num_layers=2; total time=10.5min
Model with 3 hidden layers and hidden_size 32 has 12201 trainable parameters.
Epoch [1/30] - Train Loss: 0.6451, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3423, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2885, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2618, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2448, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2329, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2237, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2164, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2105, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2058, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2018, Val Loss: nan
Epoch [12/30] - Train Loss: 0.1985, Val Loss: nan
Epoch [13/30] - Train Loss: 0.1952, Val Loss: nan
Epoch [14/30] - Train Loss: 0.1927, Val Loss: nan
Epoch [15/30] - Train Loss: 0.1903, Val Loss: nan
Epoch [16/30] - Train Loss: 0.1882, Val Loss: nan
Epoch [17/30] - Train Loss: 0.1860, Val Loss: nan
Epoch [18/30] - Train Loss: 0.1843, Val Loss: nan
Epoch [19/30] - Train Loss: 0.1824, Val Loss: nan
Epoch [20/30] - Train Loss: 0.1809, Val Loss: nan
Epoch [21/30] - Train Loss: 0.1792, Val Loss: nan
Epoch [22/30] - Train Loss: 0.1780, Val Loss: nan
Epoch [23/30] - Train Loss: 0.1768, Val Loss: nan
Epoch [24/30] - Train Loss: 0.1754, Val Loss: nan
Epoch [25/30] - Train Loss: 0.1743, Val Loss: nan
Epoch [26/30] - Train Loss: 0.1734, Val Loss: nan
Epoch [27/30] - Train Loss: 0.1722, Val Loss: nan
Epoch [28/30] - Train Loss: 0.1714, Val Loss: nan
Epoch [29/30] - Train Loss: 0.1704, Val Loss: nan
Epoch [30/30] - Train Loss: 0.1697, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.0001, nn__num_layers=3; total time=11.6min
Model with 3 hidden layers and hidden_size 32 has 12201 trainable parameters.
Epoch [1/30] - Train Loss: 0.6427, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3428, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2913, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2630, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2454, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2333, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2248, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2180, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2127, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2081, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2044, Val Loss: nan
Epoch [12/30] - Train Loss: 0.2011, Val Loss: nan
Epoch [13/30] - Train Loss: 0.1980, Val Loss: nan
Epoch [14/30] - Train Loss: 0.1953, Val Loss: nan
Epoch [15/30] - Train Loss: 0.1931, Val Loss: nan
Epoch [16/30] - Train Loss: 0.1909, Val Loss: nan
Epoch [17/30] - Train Loss: 0.1890, Val Loss: nan
Epoch [18/30] - Train Loss: 0.1872, Val Loss: nan
Epoch [19/30] - Train Loss: 0.1855, Val Loss: nan
Epoch [20/30] - Train Loss: 0.1839, Val Loss: nan
Epoch [21/30] - Train Loss: 0.1825, Val Loss: nan
Epoch [22/30] - Train Loss: 0.1810, Val Loss: nan
Epoch [23/30] - Train Loss: 0.1798, Val Loss: nan
Epoch [24/30] - Train Loss: 0.1782, Val Loss: nan
Epoch [25/30] - Train Loss: 0.1774, Val Loss: nan
Epoch [26/30] - Train Loss: 0.1764, Val Loss: nan
Epoch [27/30] - Train Loss: 0.1753, Val Loss: nan
Epoch [28/30] - Train Loss: 0.1746, Val Loss: nan
Epoch [29/30] - Train Loss: 0.1736, Val Loss: nan
Epoch [30/30] - Train Loss: 0.1726, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.0001, nn__num_layers=3; total time=11.4min
Model with 3 hidden layers and hidden_size 32 has 12201 trainable parameters.
Epoch [1/30] - Train Loss: 0.6595, Val Loss: nan
Epoch [2/30] - Train Loss: 0.3457, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2931, Val Loss: nan
Epoch [4/30] - Train Loss: 0.2641, Val Loss: nan
Epoch [5/30] - Train Loss: 0.2459, Val Loss: nan
Epoch [6/30] - Train Loss: 0.2335, Val Loss: nan
Epoch [7/30] - Train Loss: 0.2242, Val Loss: nan
Epoch [8/30] - Train Loss: 0.2169, Val Loss: nan
Epoch [9/30] - Train Loss: 0.2112, Val Loss: nan
Epoch [10/30] - Train Loss: 0.2064, Val Loss: nan
Epoch [11/30] - Train Loss: 0.2021, Val Loss: nan
Epoch [12/30] - Train Loss: 0.1985, Val Loss: nan
Epoch [13/30] - Train Loss: 0.1952, Val Loss: nan
Epoch [14/30] - Train Loss: 0.1922, Val Loss: nan
Epoch [15/30] - Train Loss: 0.1895, Val Loss: nan
Epoch [16/30] - Train Loss: 0.1874, Val Loss: nan
Epoch [17/30] - Train Loss: 0.1853, Val Loss: nan
Epoch [18/30] - Train Loss: 0.1831, Val Loss: nan
Epoch [19/30] - Train Loss: 0.1814, Val Loss: nan
Epoch [20/30] - Train Loss: 0.1797, Val Loss: nan
Epoch [21/30] - Train Loss: 0.1783, Val Loss: nan
Epoch [22/30] - Train Loss: 0.1769, Val Loss: nan
Epoch [23/30] - Train Loss: 0.1754, Val Loss: nan
Epoch [24/30] - Train Loss: 0.1743, Val Loss: nan
Epoch [25/30] - Train Loss: 0.1729, Val Loss: nan
Epoch [26/30] - Train Loss: 0.1718, Val Loss: nan
Epoch [27/30] - Train Loss: 0.1709, Val Loss: nan
Epoch [28/30] - Train Loss: 0.1697, Val Loss: nan
Epoch [29/30] - Train Loss: 0.1690, Val Loss: nan
Epoch [30/30] - Train Loss: 0.1680, Val Loss: nan
[CV] END nn__batch_size=32, nn__epochs=30, nn__hidden_size=32, nn__learning_rate=0.0001, nn__num_layers=3; total time=11.4min
Model with 3 hidden layers and hidden_size 32 has 12201 trainable parameters.
Epoch [1/30] - Train Loss: 0.3126, Val Loss: nan
Epoch [2/30] - Train Loss: 0.2248, Val Loss: nan
Epoch [3/30] - Train Loss: 0.2073, Val Loss: nan
Epoch [4/30] - Train Loss: 0.1970, Val Loss: nan
Epoch [5/30] - Train Loss: 0.1911, Val Loss: nan
Epoch [6/30] - Train Loss: 0.1870, Val Loss: nan
Epoch [7/30] - Train Loss: 0.1840, Val Loss: nan
Epoch [8/30] - Train Loss: 0.1812, Val Loss: nan
Epoch [9/30] - Train Loss: 0.1791, Val Loss: nan
Epoch [10/30] - Train Loss: 0.1778, Val Loss: nan
Epoch [11/30] - Train Loss: 0.1758, Val Loss: nan
Epoch [12/30] - Train Loss: 0.1746, Val Loss: nan
Epoch [13/30] - Train Loss: 0.1733, Val Loss: nan
Epoch [14/30] - Train Loss: 0.1721, Val Loss: nan
Epoch [15/30] - Train Loss: 0.1712, Val Loss: nan
Epoch [16/30] - Train Loss: 0.1700, Val Loss: nan
Epoch [17/30] - Train Loss: 0.1688, Val Loss: nan
Epoch [18/30] - Train Loss: 0.1685, Val Loss: nan
Epoch [19/30] - Train Loss: 0.1680, Val Loss: nan
Epoch [20/30] - Train Loss: 0.1677, Val Loss: nan
Epoch [21/30] - Train Loss: 0.1670, Val Loss: nan
Epoch [22/30] - Train Loss: 0.1658, Val Loss: nan
Epoch [23/30] - Train Loss: 0.1659, Val Loss: nan
Epoch [24/30] - Train Loss: 0.1654, Val Loss: nan
Epoch [25/30] - Train Loss: 0.1648, Val Loss: nan
Epoch [26/30] - Train Loss: 0.1646, Val Loss: nan
Epoch [27/30] - Train Loss: 0.1642, Val Loss: nan
Epoch [28/30] - Train Loss: 0.1635, Val Loss: nan
Epoch [29/30] - Train Loss: 0.1631, Val Loss: nan
Epoch [30/30] - Train Loss: 0.1632, Val Loss: nan
Grid search complete.
Best NN Pipeline Parameters: {'nn__batch_size': 32, 'nn__epochs': 30, 'nn__hidden_size': 32, 'nn__learning_rate': 0.001, 'nn__num_layers': 3}
Re-fitting best pipeline on entire training set with 100 epochs...
Model with 3 hidden layers and hidden_size 32 has 12201 trainable parameters.
Epoch [1/100] - Train Loss: 0.3175, Val Loss: nan
Epoch [2/100] - Train Loss: 0.2253, Val Loss: nan
Epoch [3/100] - Train Loss: 0.2079, Val Loss: nan
Epoch [4/100] - Train Loss: 0.1991, Val Loss: nan
Epoch [5/100] - Train Loss: 0.1932, Val Loss: nan
Epoch [6/100] - Train Loss: 0.1882, Val Loss: nan
Epoch [7/100] - Train Loss: 0.1852, Val Loss: nan
Epoch [8/100] - Train Loss: 0.1820, Val Loss: nan
Epoch [9/100] - Train Loss: 0.1798, Val Loss: nan
Epoch [10/100] - Train Loss: 0.1776, Val Loss: nan
Epoch [11/100] - Train Loss: 0.1763, Val Loss: nan
Epoch [12/100] - Train Loss: 0.1748, Val Loss: nan
Epoch [13/100] - Train Loss: 0.1734, Val Loss: nan
Epoch [14/100] - Train Loss: 0.1722, Val Loss: nan
Epoch [15/100] - Train Loss: 0.1710, Val Loss: nan
Epoch [16/100] - Train Loss: 0.1705, Val Loss: nan
Epoch [17/100] - Train Loss: 0.1700, Val Loss: nan
Epoch [18/100] - Train Loss: 0.1694, Val Loss: nan
Epoch [19/100] - Train Loss: 0.1677, Val Loss: nan
Epoch [20/100] - Train Loss: 0.1675, Val Loss: nan
Epoch [21/100] - Train Loss: 0.1672, Val Loss: nan
Epoch [22/100] - Train Loss: 0.1661, Val Loss: nan
Epoch [23/100] - Train Loss: 0.1659, Val Loss: nan
Epoch [24/100] - Train Loss: 0.1655, Val Loss: nan
Epoch [25/100] - Train Loss: 0.1650, Val Loss: nan
Epoch [26/100] - Train Loss: 0.1647, Val Loss: nan
Epoch [27/100] - Train Loss: 0.1643, Val Loss: nan
Epoch [28/100] - Train Loss: 0.1635, Val Loss: nan
Epoch [29/100] - Train Loss: 0.1635, Val Loss: nan
Epoch [30/100] - Train Loss: 0.1632, Val Loss: nan
Epoch [31/100] - Train Loss: 0.1630, Val Loss: nan
Epoch [32/100] - Train Loss: 0.1625, Val Loss: nan
Epoch [33/100] - Train Loss: 0.1623, Val Loss: nan
Epoch [34/100] - Train Loss: 0.1626, Val Loss: nan
Epoch [35/100] - Train Loss: 0.1617, Val Loss: nan
Epoch [36/100] - Train Loss: 0.1615, Val Loss: nan
Epoch [37/100] - Train Loss: 0.1616, Val Loss: nan
Epoch [38/100] - Train Loss: 0.1617, Val Loss: nan
Epoch [39/100] - Train Loss: 0.1610, Val Loss: nan
Epoch [40/100] - Train Loss: 0.1610, Val Loss: nan
Epoch [41/100] - Train Loss: 0.1605, Val Loss: nan
Epoch [42/100] - Train Loss: 0.1604, Val Loss: nan
Epoch [43/100] - Train Loss: 0.1603, Val Loss: nan
Epoch [44/100] - Train Loss: 0.1597, Val Loss: nan
Epoch [45/100] - Train Loss: 0.1600, Val Loss: nan
Epoch [46/100] - Train Loss: 0.1599, Val Loss: nan
Epoch [47/100] - Train Loss: 0.1608, Val Loss: nan
Epoch [48/100] - Train Loss: 0.1591, Val Loss: nan
Epoch [49/100] - Train Loss: 0.1595, Val Loss: nan
Epoch [50/100] - Train Loss: 0.1600, Val Loss: nan
Epoch [51/100] - Train Loss: 0.1591, Val Loss: nan
Epoch [52/100] - Train Loss: 0.1592, Val Loss: nan
Epoch [53/100] - Train Loss: 0.1597, Val Loss: nan
Epoch [54/100] - Train Loss: 0.1588, Val Loss: nan
Epoch [55/100] - Train Loss: 0.1586, Val Loss: nan
Epoch [56/100] - Train Loss: 0.1587, Val Loss: nan
Epoch [57/100] - Train Loss: 0.1578, Val Loss: nan
Epoch [58/100] - Train Loss: 0.1584, Val Loss: nan
Epoch [59/100] - Train Loss: 0.1582, Val Loss: nan
Epoch [60/100] - Train Loss: 0.1586, Val Loss: nan
Epoch [61/100] - Train Loss: 0.1581, Val Loss: nan
Epoch [62/100] - Train Loss: 0.1582, Val Loss: nan
Epoch [63/100] - Train Loss: 0.1577, Val Loss: nan
Epoch [64/100] - Train Loss: 0.1575, Val Loss: nan
Epoch [65/100] - Train Loss: 0.1573, Val Loss: nan
Epoch [66/100] - Train Loss: 0.1579, Val Loss: nan
Epoch [67/100] - Train Loss: 0.1576, Val Loss: nan
Epoch [68/100] - Train Loss: 0.1578, Val Loss: nan
Epoch [69/100] - Train Loss: 0.1581, Val Loss: nan
Epoch [70/100] - Train Loss: 0.1573, Val Loss: nan
Epoch [71/100] - Train Loss: 0.1573, Val Loss: nan
Epoch [72/100] - Train Loss: 0.1572, Val Loss: nan
Epoch [73/100] - Train Loss: 0.1571, Val Loss: nan
Epoch [74/100] - Train Loss: 0.1572, Val Loss: nan
Epoch [75/100] - Train Loss: 0.1565, Val Loss: nan
Epoch [76/100] - Train Loss: 0.1567, Val Loss: nan
Epoch [77/100] - Train Loss: 0.1565, Val Loss: nan
Epoch [78/100] - Train Loss: 0.1568, Val Loss: nan
Epoch [79/100] - Train Loss: 0.1570, Val Loss: nan
Epoch [80/100] - Train Loss: 0.1571, Val Loss: nan
Epoch [81/100] - Train Loss: 0.1568, Val Loss: nan
Epoch [82/100] - Train Loss: 0.1579, Val Loss: nan
Epoch [83/100] - Train Loss: 0.1572, Val Loss: nan
Epoch [84/100] - Train Loss: 0.1576, Val Loss: nan
Epoch [85/100] - Train Loss: 0.1576, Val Loss: nan
Epoch [86/100] - Train Loss: 0.1577, Val Loss: nan
Epoch [87/100] - Train Loss: 0.1573, Val Loss: nan
Epoch [88/100] - Train Loss: 0.1570, Val Loss: nan
Epoch [89/100] - Train Loss: 0.1573, Val Loss: nan
Epoch [90/100] - Train Loss: 0.1577, Val Loss: nan
Epoch [91/100] - Train Loss: 0.1577, Val Loss: nan
Epoch [92/100] - Train Loss: 0.1565, Val Loss: nan
Epoch [93/100] - Train Loss: 0.1572, Val Loss: nan
Epoch [94/100] - Train Loss: 0.1573, Val Loss: nan
Epoch [95/100] - Train Loss: 0.1578, Val Loss: nan
Epoch [96/100] - Train Loss: 0.1573, Val Loss: nan
Epoch [97/100] - Train Loss: 0.1574, Val Loss: nan
Epoch [98/100] - Train Loss: 0.1573, Val Loss: nan
Epoch [99/100] - Train Loss: 0.1576, Val Loss: nan
Epoch [100/100] - Train Loss: 0.1574, Val Loss: nan
Performing 5-fold CV with the best hyperparameters for uncertainty estimates...
Model with 3 hidden layers and hidden_size 32 has 12201 trainable parameters.
Epoch [1/100] - Train Loss: 0.3259, Val Loss: 0.2550
Epoch [2/100] - Train Loss: 0.2330, Val Loss: 0.2341
Epoch [3/100] - Train Loss: 0.2140, Val Loss: 0.2108
Epoch [4/100] - Train Loss: 0.2029, Val Loss: 0.2061
Epoch [5/100] - Train Loss: 0.1950, Val Loss: 0.2101
Epoch [6/100] - Train Loss: 0.1900, Val Loss: 0.1956
Epoch [7/100] - Train Loss: 0.1856, Val Loss: 0.1894
Epoch [8/100] - Train Loss: 0.1823, Val Loss: 0.1934
Epoch [9/100] - Train Loss: 0.1795, Val Loss: 0.1862
Epoch [10/100] - Train Loss: 0.1775, Val Loss: 0.1988
Epoch [11/100] - Train Loss: 0.1758, Val Loss: 0.1863
Epoch [12/100] - Train Loss: 0.1740, Val Loss: 0.1862
Epoch [13/100] - Train Loss: 0.1728, Val Loss: 0.1841
Epoch [14/100] - Train Loss: 0.1715, Val Loss: 0.1844
Epoch [15/100] - Train Loss: 0.1704, Val Loss: 0.1805
Epoch [16/100] - Train Loss: 0.1692, Val Loss: 0.1840
Epoch [17/100] - Train Loss: 0.1679, Val Loss: 0.1820
Epoch [18/100] - Train Loss: 0.1670, Val Loss: 0.1846
Epoch [19/100] - Train Loss: 0.1665, Val Loss: 0.1896
Epoch [20/100] - Train Loss: 0.1658, Val Loss: 0.1820
Epoch [21/100] - Train Loss: 0.1648, Val Loss: 0.1816
Epoch [22/100] - Train Loss: 0.1643, Val Loss: 0.1847
Epoch [23/100] - Train Loss: 0.1632, Val Loss: 0.1900
Epoch [24/100] - Train Loss: 0.1632, Val Loss: 0.1853
Epoch [25/100] - Train Loss: 0.1624, Val Loss: 0.1862
Epoch [26/100] - Train Loss: 0.1620, Val Loss: 0.1841
Epoch [27/100] - Train Loss: 0.1620, Val Loss: 0.1914
Epoch [28/100] - Train Loss: 0.1612, Val Loss: 0.1816
Epoch [29/100] - Train Loss: 0.1613, Val Loss: 0.1828
Epoch [30/100] - Train Loss: 0.1606, Val Loss: 0.1805
Epoch [31/100] - Train Loss: 0.1606, Val Loss: 0.1880
Epoch [32/100] - Train Loss: 0.1597, Val Loss: 0.1820
Epoch [33/100] - Train Loss: 0.1597, Val Loss: 0.1843
Epoch [34/100] - Train Loss: 0.1591, Val Loss: 0.1850
Epoch [35/100] - Train Loss: 0.1596, Val Loss: 0.1828
Epoch [36/100] - Train Loss: 0.1588, Val Loss: 0.1798
Epoch [37/100] - Train Loss: 0.1589, Val Loss: 0.1821
Epoch [38/100] - Train Loss: 0.1588, Val Loss: 0.1925
Epoch [39/100] - Train Loss: 0.1582, Val Loss: 0.1872
Epoch [40/100] - Train Loss: 0.1583, Val Loss: 0.1910
Epoch [41/100] - Train Loss: 0.1580, Val Loss: 0.1884
Epoch [42/100] - Train Loss: 0.1580, Val Loss: 0.1819
Epoch [43/100] - Train Loss: 0.1576, Val Loss: 0.1846
Epoch [44/100] - Train Loss: 0.1573, Val Loss: 0.1907
Epoch [45/100] - Train Loss: 0.1576, Val Loss: 0.1838
Epoch [46/100] - Train Loss: 0.1571, Val Loss: 0.1874
Epoch [47/100] - Train Loss: 0.1568, Val Loss: 0.1919
Epoch [48/100] - Train Loss: 0.1572, Val Loss: 0.1763
Epoch [49/100] - Train Loss: 0.1568, Val Loss: 0.1823
Epoch [50/100] - Train Loss: 0.1564, Val Loss: 0.1872
Epoch [51/100] - Train Loss: 0.1562, Val Loss: 0.1817
Epoch [52/100] - Train Loss: 0.1563, Val Loss: 0.1893
Epoch [53/100] - Train Loss: 0.1562, Val Loss: 0.1830
Epoch [54/100] - Train Loss: 0.1561, Val Loss: 0.1797
Epoch [55/100] - Train Loss: 0.1565, Val Loss: 0.1800
Epoch [56/100] - Train Loss: 0.1553, Val Loss: 0.1827
Epoch [57/100] - Train Loss: 0.1554, Val Loss: 0.1919
Epoch [58/100] - Train Loss: 0.1555, Val Loss: 0.1969
Epoch [59/100] - Train Loss: 0.1554, Val Loss: 0.1933
Epoch [60/100] - Train Loss: 0.1553, Val Loss: 0.1875
Epoch [61/100] - Train Loss: 0.1556, Val Loss: 0.1869
Epoch [62/100] - Train Loss: 0.1552, Val Loss: 0.1932
Epoch [63/100] - Train Loss: 0.1549, Val Loss: 0.1932
Epoch [64/100] - Train Loss: 0.1577, Val Loss: 0.1814
Epoch [65/100] - Train Loss: 0.1549, Val Loss: 0.1937
Epoch [66/100] - Train Loss: 0.1551, Val Loss: 0.1892
Epoch [67/100] - Train Loss: 0.1549, Val Loss: 0.2066
Epoch [68/100] - Train Loss: 0.1547, Val Loss: 0.1867
Epoch [69/100] - Train Loss: 0.1549, Val Loss: 0.1908
Epoch [70/100] - Train Loss: 0.1542, Val Loss: 0.1866
Epoch [71/100] - Train Loss: 0.1550, Val Loss: 0.1982
Epoch [72/100] - Train Loss: 0.1548, Val Loss: 0.2017
Epoch [73/100] - Train Loss: 0.1544, Val Loss: 0.2086
Epoch [74/100] - Train Loss: 0.1562, Val Loss: 0.1988
Epoch [75/100] - Train Loss: 0.1543, Val Loss: 0.1971
Epoch [76/100] - Train Loss: 0.1548, Val Loss: 0.2015
Epoch [77/100] - Train Loss: 0.1551, Val Loss: 0.1913
Epoch [78/100] - Train Loss: 0.1548, Val Loss: 0.1946
Epoch [79/100] - Train Loss: 0.1544, Val Loss: 0.1923
Epoch [80/100] - Train Loss: 0.1545, Val Loss: 0.1916
Epoch [81/100] - Train Loss: 0.1570, Val Loss: 0.2078
Epoch [82/100] - Train Loss: 0.1544, Val Loss: 0.2090
Epoch [83/100] - Train Loss: 0.1539, Val Loss: 0.1970
Epoch [84/100] - Train Loss: 0.1540, Val Loss: 0.2078
Epoch [85/100] - Train Loss: 0.1532, Val Loss: 0.1960
Epoch [86/100] - Train Loss: 0.1548, Val Loss: 0.1929
Epoch [87/100] - Train Loss: 0.1541, Val Loss: 0.2033
Epoch [88/100] - Train Loss: 0.1534, Val Loss: 0.2063
Epoch [89/100] - Train Loss: 0.1543, Val Loss: 0.1867
Epoch [90/100] - Train Loss: 0.1534, Val Loss: 0.1893
Epoch [91/100] - Train Loss: 0.1535, Val Loss: 0.1905
Epoch [92/100] - Train Loss: 0.1537, Val Loss: 0.1976
Epoch [93/100] - Train Loss: 0.1532, Val Loss: 0.2130
Epoch [94/100] - Train Loss: 0.1538, Val Loss: 0.2159
Epoch [95/100] - Train Loss: 0.1547, Val Loss: 0.2224
Epoch [96/100] - Train Loss: 0.1539, Val Loss: 0.1961
Epoch [97/100] - Train Loss: 0.1673, Val Loss: 0.1979
Epoch [98/100] - Train Loss: 0.1525, Val Loss: 0.2110
Epoch [99/100] - Train Loss: 0.1533, Val Loss: 0.2019
Epoch [100/100] - Train Loss: 0.1536, Val Loss: 0.2005
Fold 1 complete. Validation Accuracy: 0.9424
Model with 3 hidden layers and hidden_size 32 has 12201 trainable parameters.
Epoch [1/100] - Train Loss: 0.3320, Val Loss: 0.2394
Epoch [2/100] - Train Loss: 0.2311, Val Loss: 0.2544
Epoch [3/100] - Train Loss: 0.2116, Val Loss: 0.2100
Epoch [4/100] - Train Loss: 0.2014, Val Loss: 0.2061
Epoch [5/100] - Train Loss: 0.1944, Val Loss: 0.2024
Epoch [6/100] - Train Loss: 0.1895, Val Loss: 0.2075
Epoch [7/100] - Train Loss: 0.1859, Val Loss: 0.2053
Epoch [8/100] - Train Loss: 0.1831, Val Loss: 0.2075
Epoch [9/100] - Train Loss: 0.1808, Val Loss: 0.1870
Epoch [10/100] - Train Loss: 0.1788, Val Loss: 0.1950
Epoch [11/100] - Train Loss: 0.1770, Val Loss: 0.1905
Epoch [12/100] - Train Loss: 0.1755, Val Loss: 0.1908
Epoch [13/100] - Train Loss: 0.1739, Val Loss: 0.1830
Epoch [14/100] - Train Loss: 0.1734, Val Loss: 0.1893
Epoch [15/100] - Train Loss: 0.1719, Val Loss: 0.1845
Epoch [16/100] - Train Loss: 0.1710, Val Loss: 0.1778
Epoch [17/100] - Train Loss: 0.1698, Val Loss: 0.1846
Epoch [18/100] - Train Loss: 0.1690, Val Loss: 0.1819
Epoch [19/100] - Train Loss: 0.1686, Val Loss: 0.1800
Epoch [20/100] - Train Loss: 0.1680, Val Loss: 0.1816
Epoch [21/100] - Train Loss: 0.1670, Val Loss: 0.1844
Epoch [22/100] - Train Loss: 0.1663, Val Loss: 0.1813
Epoch [23/100] - Train Loss: 0.1659, Val Loss: 0.1787
Epoch [24/100] - Train Loss: 0.1652, Val Loss: 0.1773
Epoch [25/100] - Train Loss: 0.1650, Val Loss: 0.1765
Epoch [26/100] - Train Loss: 0.1638, Val Loss: 0.1877
Epoch [27/100] - Train Loss: 0.1638, Val Loss: 0.1878
Epoch [28/100] - Train Loss: 0.1640, Val Loss: 0.1803
Epoch [29/100] - Train Loss: 0.1628, Val Loss: 0.1810
Epoch [30/100] - Train Loss: 0.1623, Val Loss: 0.1723
Epoch [31/100] - Train Loss: 0.1618, Val Loss: 0.1841
Epoch [32/100] - Train Loss: 0.1617, Val Loss: 0.1784
Epoch [33/100] - Train Loss: 0.1611, Val Loss: 0.1893
Epoch [34/100] - Train Loss: 0.1612, Val Loss: 0.1762
Epoch [35/100] - Train Loss: 0.1606, Val Loss: 0.1728
Epoch [36/100] - Train Loss: 0.1604, Val Loss: 0.1804
Epoch [37/100] - Train Loss: 0.1603, Val Loss: 0.1792
Epoch [38/100] - Train Loss: 0.1600, Val Loss: 0.1762
Epoch [39/100] - Train Loss: 0.1599, Val Loss: 0.1793
Epoch [40/100] - Train Loss: 0.1592, Val Loss: 0.1867
Epoch [41/100] - Train Loss: 0.1590, Val Loss: 0.1768
Epoch [42/100] - Train Loss: 0.1590, Val Loss: 0.1757
Epoch [43/100] - Train Loss: 0.1584, Val Loss: 0.1745
Epoch [44/100] - Train Loss: 0.1591, Val Loss: 0.1749
Epoch [45/100] - Train Loss: 0.1585, Val Loss: 0.1789
Epoch [46/100] - Train Loss: 0.1587, Val Loss: 0.1741
Epoch [47/100] - Train Loss: 0.1579, Val Loss: 0.1769
Epoch [48/100] - Train Loss: 0.1577, Val Loss: 0.1800
Epoch [49/100] - Train Loss: 0.1573, Val Loss: 0.1775
Epoch [50/100] - Train Loss: 0.1573, Val Loss: 0.1787
Epoch [51/100] - Train Loss: 0.1574, Val Loss: 0.1778
Epoch [52/100] - Train Loss: 0.1574, Val Loss: 0.1752
Epoch [53/100] - Train Loss: 0.1572, Val Loss: 0.1742
Epoch [54/100] - Train Loss: 0.1567, Val Loss: 0.1768
Epoch [55/100] - Train Loss: 0.1571, Val Loss: 0.1805
Epoch [56/100] - Train Loss: 0.1566, Val Loss: 0.1869
Epoch [57/100] - Train Loss: 0.1574, Val Loss: 0.1755
Epoch [58/100] - Train Loss: 0.1561, Val Loss: 0.1832
Epoch [59/100] - Train Loss: 0.1561, Val Loss: 0.1805
Epoch [60/100] - Train Loss: 0.1561, Val Loss: 0.1771
Epoch [61/100] - Train Loss: 0.1562, Val Loss: 0.1750
Epoch [62/100] - Train Loss: 0.1562, Val Loss: 0.1792
Epoch [63/100] - Train Loss: 0.1561, Val Loss: 0.1810
Epoch [64/100] - Train Loss: 0.1561, Val Loss: 0.1802
Epoch [65/100] - Train Loss: 0.1559, Val Loss: 0.1802
Epoch [66/100] - Train Loss: 0.1556, Val Loss: 0.1797
Epoch [67/100] - Train Loss: 0.1564, Val Loss: 0.1859
Epoch [68/100] - Train Loss: 0.1550, Val Loss: 0.1793
Epoch [69/100] - Train Loss: 0.1562, Val Loss: 0.1787
Epoch [70/100] - Train Loss: 0.1555, Val Loss: 0.1863
Epoch [71/100] - Train Loss: 0.1565, Val Loss: 0.1796
Epoch [72/100] - Train Loss: 0.1559, Val Loss: 0.1800
Epoch [73/100] - Train Loss: 0.1552, Val Loss: 0.1792
Epoch [74/100] - Train Loss: 0.1553, Val Loss: 0.1737
Epoch [75/100] - Train Loss: 0.1550, Val Loss: 0.1767
Epoch [76/100] - Train Loss: 0.1545, Val Loss: 0.1784
Epoch [77/100] - Train Loss: 0.1550, Val Loss: 0.1763
Epoch [78/100] - Train Loss: 0.1561, Val Loss: 0.1871
Epoch [79/100] - Train Loss: 0.1551, Val Loss: 0.1838
Epoch [80/100] - Train Loss: 0.1550, Val Loss: 0.1746
Epoch [81/100] - Train Loss: 0.1560, Val Loss: 0.1748
Epoch [82/100] - Train Loss: 0.1552, Val Loss: 0.1800
Epoch [83/100] - Train Loss: 0.1557, Val Loss: 0.1811
Epoch [84/100] - Train Loss: 0.1542, Val Loss: 0.1816
Epoch [85/100] - Train Loss: 0.1554, Val Loss: 0.1813
Epoch [86/100] - Train Loss: 0.1547, Val Loss: 0.1772
Epoch [87/100] - Train Loss: 0.1547, Val Loss: 0.1808
Epoch [88/100] - Train Loss: 0.1545, Val Loss: 0.1745
Epoch [89/100] - Train Loss: 0.1545, Val Loss: 0.1747
Epoch [90/100] - Train Loss: 0.1548, Val Loss: 0.1802
Epoch [91/100] - Train Loss: 0.1542, Val Loss: 0.1819
Epoch [92/100] - Train Loss: 0.1549, Val Loss: 0.1815
Epoch [93/100] - Train Loss: 0.1546, Val Loss: 0.1790
Epoch [94/100] - Train Loss: 0.1544, Val Loss: 0.1839
Epoch [95/100] - Train Loss: 0.1550, Val Loss: 0.1859
Epoch [96/100] - Train Loss: 0.1539, Val Loss: 0.1801
Epoch [97/100] - Train Loss: 0.1540, Val Loss: 0.1801
Epoch [98/100] - Train Loss: 0.1540, Val Loss: 0.1862
Epoch [99/100] - Train Loss: 0.1541, Val Loss: 0.1783
Epoch [100/100] - Train Loss: 0.1543, Val Loss: 0.1807
Fold 2 complete. Validation Accuracy: 0.9421
Model with 3 hidden layers and hidden_size 32 has 12201 trainable parameters.
Epoch [1/100] - Train Loss: 0.3282, Val Loss: 0.2487
Epoch [2/100] - Train Loss: 0.2343, Val Loss: 0.2221
Epoch [3/100] - Train Loss: 0.2156, Val Loss: 0.2101
Epoch [4/100] - Train Loss: 0.2050, Val Loss: 0.2027
Epoch [5/100] - Train Loss: 0.1978, Val Loss: 0.2058
Epoch [6/100] - Train Loss: 0.1929, Val Loss: 0.2006
Epoch [7/100] - Train Loss: 0.1884, Val Loss: 0.1983
Epoch [8/100] - Train Loss: 0.1850, Val Loss: 0.1894
Epoch [9/100] - Train Loss: 0.1824, Val Loss: 0.1889
Epoch [10/100] - Train Loss: 0.1806, Val Loss: 0.1955
Epoch [11/100] - Train Loss: 0.1785, Val Loss: 0.1835
Epoch [12/100] - Train Loss: 0.1768, Val Loss: 0.1911
Epoch [13/100] - Train Loss: 0.1753, Val Loss: 0.1897
Epoch [14/100] - Train Loss: 0.1741, Val Loss: 0.1820
Epoch [15/100] - Train Loss: 0.1725, Val Loss: 0.1853
Epoch [16/100] - Train Loss: 0.1719, Val Loss: 0.1848
Epoch [17/100] - Train Loss: 0.1705, Val Loss: 0.1901
Epoch [18/100] - Train Loss: 0.1693, Val Loss: 0.1795
Epoch [19/100] - Train Loss: 0.1685, Val Loss: 0.1816
Epoch [20/100] - Train Loss: 0.1681, Val Loss: 0.1785
Epoch [21/100] - Train Loss: 0.1672, Val Loss: 0.1775
Epoch [22/100] - Train Loss: 0.1663, Val Loss: 0.1791
Epoch [23/100] - Train Loss: 0.1658, Val Loss: 0.1826
Epoch [24/100] - Train Loss: 0.1652, Val Loss: 0.1760
Epoch [25/100] - Train Loss: 0.1649, Val Loss: 0.1931
Epoch [26/100] - Train Loss: 0.1645, Val Loss: 0.1794
Epoch [27/100] - Train Loss: 0.1637, Val Loss: 0.1726
Epoch [28/100] - Train Loss: 0.1635, Val Loss: 0.1750
Epoch [29/100] - Train Loss: 0.1625, Val Loss: 0.1857
Epoch [30/100] - Train Loss: 0.1627, Val Loss: 0.1760
Epoch [31/100] - Train Loss: 0.1625, Val Loss: 0.1742
Epoch [32/100] - Train Loss: 0.1616, Val Loss: 0.1815
Epoch [33/100] - Train Loss: 0.1614, Val Loss: 0.1847
Epoch [34/100] - Train Loss: 0.1613, Val Loss: 0.1792
Epoch [35/100] - Train Loss: 0.1609, Val Loss: 0.1815
Epoch [36/100] - Train Loss: 0.1614, Val Loss: 0.1739
Epoch [37/100] - Train Loss: 0.1605, Val Loss: 0.1792
Epoch [38/100] - Train Loss: 0.1607, Val Loss: 0.1770
Epoch [39/100] - Train Loss: 0.1597, Val Loss: 0.1768
Epoch [40/100] - Train Loss: 0.1594, Val Loss: 0.1828
Epoch [41/100] - Train Loss: 0.1598, Val Loss: 0.1780
Epoch [42/100] - Train Loss: 0.1588, Val Loss: 0.1821
Epoch [43/100] - Train Loss: 0.1590, Val Loss: 0.1778
Epoch [44/100] - Train Loss: 0.1588, Val Loss: 0.1765
Epoch [45/100] - Train Loss: 0.1587, Val Loss: 0.1761
Epoch [46/100] - Train Loss: 0.1586, Val Loss: 0.1820
Epoch [47/100] - Train Loss: 0.1584, Val Loss: 0.1905
Epoch [48/100] - Train Loss: 0.1580, Val Loss: 0.1865
Epoch [49/100] - Train Loss: 0.1586, Val Loss: 0.1832
Epoch [50/100] - Train Loss: 0.1579, Val Loss: 0.1804
Epoch [51/100] - Train Loss: 0.1580, Val Loss: 0.1773
Epoch [52/100] - Train Loss: 0.1574, Val Loss: 0.1836
Epoch [53/100] - Train Loss: 0.1573, Val Loss: 0.1814
Epoch [54/100] - Train Loss: 0.1576, Val Loss: 0.1851
Epoch [55/100] - Train Loss: 0.1569, Val Loss: 0.1763
Epoch [56/100] - Train Loss: 0.1571, Val Loss: 0.1788
Epoch [57/100] - Train Loss: 0.1570, Val Loss: 0.1776
Epoch [58/100] - Train Loss: 0.1566, Val Loss: 0.1776
Epoch [59/100] - Train Loss: 0.1569, Val Loss: 0.1840
Epoch [60/100] - Train Loss: 0.1567, Val Loss: 0.1783
Epoch [61/100] - Train Loss: 0.1560, Val Loss: 0.1803
Epoch [62/100] - Train Loss: 0.1562, Val Loss: 0.1860
Epoch [63/100] - Train Loss: 0.1570, Val Loss: 0.1863
Epoch [64/100] - Train Loss: 0.1559, Val Loss: 0.1812
Epoch [65/100] - Train Loss: 0.1564, Val Loss: 0.1822
Epoch [66/100] - Train Loss: 0.1561, Val Loss: 0.1849
Epoch [67/100] - Train Loss: 0.1560, Val Loss: 0.1790
Epoch [68/100] - Train Loss: 0.1559, Val Loss: 0.1868
Epoch [69/100] - Train Loss: 0.1561, Val Loss: 0.1793
Epoch [70/100] - Train Loss: 0.1561, Val Loss: 0.1757
Epoch [71/100] - Train Loss: 0.1555, Val Loss: 0.1815
Epoch [72/100] - Train Loss: 0.1556, Val Loss: 0.1924
Epoch [73/100] - Train Loss: 0.1554, Val Loss: 0.1809
Epoch [74/100] - Train Loss: 0.1555, Val Loss: 0.1804
Epoch [75/100] - Train Loss: 0.1552, Val Loss: 0.1774
Epoch [76/100] - Train Loss: 0.1558, Val Loss: 0.1815
Epoch [77/100] - Train Loss: 0.1548, Val Loss: 0.1805
Epoch [78/100] - Train Loss: 0.1546, Val Loss: 0.1797
Epoch [79/100] - Train Loss: 0.1548, Val Loss: 0.1836
Epoch [80/100] - Train Loss: 0.1548, Val Loss: 0.1771
Epoch [81/100] - Train Loss: 0.1547, Val Loss: 0.1807
Epoch [82/100] - Train Loss: 0.1545, Val Loss: 0.1911
Epoch [83/100] - Train Loss: 0.1546, Val Loss: 0.1832
Epoch [84/100] - Train Loss: 0.1543, Val Loss: 0.1838
Epoch [85/100] - Train Loss: 0.1545, Val Loss: 0.1839
Epoch [86/100] - Train Loss: 0.1546, Val Loss: 0.1818
Epoch [87/100] - Train Loss: 0.1540, Val Loss: 0.1809
Epoch [88/100] - Train Loss: 0.1542, Val Loss: 0.1848
Epoch [89/100] - Train Loss: 0.1544, Val Loss: 0.1849
Epoch [90/100] - Train Loss: 0.1542, Val Loss: 0.1849
Epoch [91/100] - Train Loss: 0.1539, Val Loss: 0.1794
Epoch [92/100] - Train Loss: 0.1538, Val Loss: 0.1836
Epoch [93/100] - Train Loss: 0.1536, Val Loss: 0.1886
Epoch [94/100] - Train Loss: 0.1542, Val Loss: 0.1870
Epoch [95/100] - Train Loss: 0.1547, Val Loss: 0.1829
Epoch [96/100] - Train Loss: 0.1544, Val Loss: 0.1843
Epoch [97/100] - Train Loss: 0.1535, Val Loss: 0.1804
Epoch [98/100] - Train Loss: 0.1533, Val Loss: 0.1873
Epoch [99/100] - Train Loss: 0.1541, Val Loss: 0.1939
Epoch [100/100] - Train Loss: 0.1538, Val Loss: 0.2044
Fold 3 complete. Validation Accuracy: 0.9394
Model with 3 hidden layers and hidden_size 32 has 12201 trainable parameters.
Epoch [1/100] - Train Loss: 0.3305, Val Loss: 0.2522
Epoch [2/100] - Train Loss: 0.2319, Val Loss: 0.2223
Epoch [3/100] - Train Loss: 0.2127, Val Loss: 0.2053
Epoch [4/100] - Train Loss: 0.2023, Val Loss: 0.1995
Epoch [5/100] - Train Loss: 0.1951, Val Loss: 0.1942
Epoch [6/100] - Train Loss: 0.1902, Val Loss: 0.1953
Epoch [7/100] - Train Loss: 0.1864, Val Loss: 0.1927
Epoch [8/100] - Train Loss: 0.1832, Val Loss: 0.1890
Epoch [9/100] - Train Loss: 0.1803, Val Loss: 0.1863
Epoch [10/100] - Train Loss: 0.1781, Val Loss: 0.1866
Epoch [11/100] - Train Loss: 0.1764, Val Loss: 0.1860
Epoch [12/100] - Train Loss: 0.1750, Val Loss: 0.1849
Epoch [13/100] - Train Loss: 0.1733, Val Loss: 0.1797
Epoch [14/100] - Train Loss: 0.1724, Val Loss: 0.1885
Epoch [15/100] - Train Loss: 0.1710, Val Loss: 0.1843
Epoch [16/100] - Train Loss: 0.1703, Val Loss: 0.1805
Epoch [17/100] - Train Loss: 0.1692, Val Loss: 0.1797
Epoch [18/100] - Train Loss: 0.1677, Val Loss: 0.1743
Epoch [19/100] - Train Loss: 0.1675, Val Loss: 0.1822
Epoch [20/100] - Train Loss: 0.1667, Val Loss: 0.1816
Epoch [21/100] - Train Loss: 0.1663, Val Loss: 0.1784
Epoch [22/100] - Train Loss: 0.1651, Val Loss: 0.1829
Epoch [23/100] - Train Loss: 0.1648, Val Loss: 0.1814
Epoch [24/100] - Train Loss: 0.1638, Val Loss: 0.1772
Epoch [25/100] - Train Loss: 0.1637, Val Loss: 0.1730
Epoch [26/100] - Train Loss: 0.1632, Val Loss: 0.1785
Epoch [27/100] - Train Loss: 0.1621, Val Loss: 0.1898
Epoch [28/100] - Train Loss: 0.1623, Val Loss: 0.1762
Epoch [29/100] - Train Loss: 0.1616, Val Loss: 0.1780
Epoch [30/100] - Train Loss: 0.1609, Val Loss: 0.1790
Epoch [31/100] - Train Loss: 0.1612, Val Loss: 0.1752
Epoch [32/100] - Train Loss: 0.1605, Val Loss: 0.1771
Epoch [33/100] - Train Loss: 0.1597, Val Loss: 0.1799
Epoch [34/100] - Train Loss: 0.1596, Val Loss: 0.1741
Epoch [35/100] - Train Loss: 0.1596, Val Loss: 0.1742
Epoch [36/100] - Train Loss: 0.1589, Val Loss: 0.1793
Epoch [37/100] - Train Loss: 0.1590, Val Loss: 0.1753
Epoch [38/100] - Train Loss: 0.1588, Val Loss: 0.1747
Epoch [39/100] - Train Loss: 0.1589, Val Loss: 0.1763
Epoch [40/100] - Train Loss: 0.1580, Val Loss: 0.1791
Epoch [41/100] - Train Loss: 0.1577, Val Loss: 0.1741
Epoch [42/100] - Train Loss: 0.1578, Val Loss: 0.1727
Epoch [43/100] - Train Loss: 0.1578, Val Loss: 0.1788
Epoch [44/100] - Train Loss: 0.1575, Val Loss: 0.1769
Epoch [45/100] - Train Loss: 0.1569, Val Loss: 0.1812
Epoch [46/100] - Train Loss: 0.1573, Val Loss: 0.1747
Epoch [47/100] - Train Loss: 0.1567, Val Loss: 0.1772
Epoch [48/100] - Train Loss: 0.1566, Val Loss: 0.1758
Epoch [49/100] - Train Loss: 0.1568, Val Loss: 0.1759
Epoch [50/100] - Train Loss: 0.1563, Val Loss: 0.1766
Epoch [51/100] - Train Loss: 0.1560, Val Loss: 0.1786
Epoch [52/100] - Train Loss: 0.1556, Val Loss: 0.1786
Epoch [53/100] - Train Loss: 0.1562, Val Loss: 0.1729
Epoch [54/100] - Train Loss: 0.1557, Val Loss: 0.1750
Epoch [55/100] - Train Loss: 0.1561, Val Loss: 0.1918
Epoch [56/100] - Train Loss: 0.1553, Val Loss: 0.1723
Epoch [57/100] - Train Loss: 0.1555, Val Loss: 0.1745
Epoch [58/100] - Train Loss: 0.1553, Val Loss: 0.1777
Epoch [59/100] - Train Loss: 0.1549, Val Loss: 0.1785
Epoch [60/100] - Train Loss: 0.1555, Val Loss: 0.1739
Epoch [61/100] - Train Loss: 0.1547, Val Loss: 0.1738
Epoch [62/100] - Train Loss: 0.1544, Val Loss: 0.1815
Epoch [63/100] - Train Loss: 0.1547, Val Loss: 0.1726
Epoch [64/100] - Train Loss: 0.1540, Val Loss: 0.1747
Epoch [65/100] - Train Loss: 0.1547, Val Loss: 0.1851
Epoch [66/100] - Train Loss: 0.1542, Val Loss: 0.1733
Epoch [67/100] - Train Loss: 0.1544, Val Loss: 0.1799
Epoch [68/100] - Train Loss: 0.1541, Val Loss: 0.1737
Epoch [69/100] - Train Loss: 0.1538, Val Loss: 0.1742
Epoch [70/100] - Train Loss: 0.1535, Val Loss: 0.1723
Epoch [71/100] - Train Loss: 0.1538, Val Loss: 0.1740
Epoch [72/100] - Train Loss: 0.1539, Val Loss: 0.1831
Epoch [73/100] - Train Loss: 0.1531, Val Loss: 0.1803
Epoch [74/100] - Train Loss: 0.1531, Val Loss: 0.1732
Epoch [75/100] - Train Loss: 0.1538, Val Loss: 0.1778
Epoch [76/100] - Train Loss: 0.1538, Val Loss: 0.1783
Epoch [77/100] - Train Loss: 0.1531, Val Loss: 0.1845
Epoch [78/100] - Train Loss: 0.1531, Val Loss: 0.1765
Epoch [79/100] - Train Loss: 0.1530, Val Loss: 0.1777
Epoch [80/100] - Train Loss: 0.1530, Val Loss: 0.1806
Epoch [81/100] - Train Loss: 0.1532, Val Loss: 0.1835
Epoch [82/100] - Train Loss: 0.1530, Val Loss: 0.1735
Epoch [83/100] - Train Loss: 0.1530, Val Loss: 0.1789
Epoch [84/100] - Train Loss: 0.1530, Val Loss: 0.1756
Epoch [85/100] - Train Loss: 0.1532, Val Loss: 0.1802
Epoch [86/100] - Train Loss: 0.1529, Val Loss: 0.1822
Epoch [87/100] - Train Loss: 0.1533, Val Loss: 0.1786
Epoch [88/100] - Train Loss: 0.1535, Val Loss: 0.1824
Epoch [89/100] - Train Loss: 0.1532, Val Loss: 0.1807
Epoch [90/100] - Train Loss: 0.1531, Val Loss: 0.1860
Epoch [91/100] - Train Loss: 0.1528, Val Loss: 0.1796
Epoch [92/100] - Train Loss: 0.1528, Val Loss: 0.1819
Epoch [93/100] - Train Loss: 0.1534, Val Loss: 0.1778
Epoch [94/100] - Train Loss: 0.1528, Val Loss: 0.1790
Epoch [95/100] - Train Loss: 0.1530, Val Loss: 0.1793
Epoch [96/100] - Train Loss: 0.1536, Val Loss: 0.1827
Epoch [97/100] - Train Loss: 0.1528, Val Loss: 0.1781
Epoch [98/100] - Train Loss: 0.1530, Val Loss: 0.1806
Epoch [99/100] - Train Loss: 0.1527, Val Loss: 0.1963
Epoch [100/100] - Train Loss: 0.1538, Val Loss: 0.1945
Fold 4 complete. Validation Accuracy: 0.9396
Model with 3 hidden layers and hidden_size 32 has 12201 trainable parameters.
Epoch [1/100] - Train Loss: 0.3320, Val Loss: 0.2570
Epoch [2/100] - Train Loss: 0.2335, Val Loss: 0.2210
Epoch [3/100] - Train Loss: 0.2153, Val Loss: 0.2041
Epoch [4/100] - Train Loss: 0.2051, Val Loss: 0.1991
Epoch [5/100] - Train Loss: 0.1976, Val Loss: 0.1959
Epoch [6/100] - Train Loss: 0.1922, Val Loss: 0.1922
Epoch [7/100] - Train Loss: 0.1885, Val Loss: 0.1893
Epoch [8/100] - Train Loss: 0.1851, Val Loss: 0.1934
Epoch [9/100] - Train Loss: 0.1825, Val Loss: 0.1946
Epoch [10/100] - Train Loss: 0.1802, Val Loss: 0.1943
Epoch [11/100] - Train Loss: 0.1787, Val Loss: 0.1910
Epoch [12/100] - Train Loss: 0.1766, Val Loss: 0.1816
Epoch [13/100] - Train Loss: 0.1756, Val Loss: 0.1826
Epoch [14/100] - Train Loss: 0.1738, Val Loss: 0.1861
Epoch [15/100] - Train Loss: 0.1734, Val Loss: 0.1806
Epoch [16/100] - Train Loss: 0.1716, Val Loss: 0.1844
Epoch [17/100] - Train Loss: 0.1710, Val Loss: 0.1852
Epoch [18/100] - Train Loss: 0.1701, Val Loss: 0.1782
Epoch [19/100] - Train Loss: 0.1689, Val Loss: 0.1812
Epoch [20/100] - Train Loss: 0.1685, Val Loss: 0.1766
Epoch [21/100] - Train Loss: 0.1687, Val Loss: 0.1840
Epoch [22/100] - Train Loss: 0.1673, Val Loss: 0.1759
Epoch [23/100] - Train Loss: 0.1669, Val Loss: 0.1767
Epoch [24/100] - Train Loss: 0.1658, Val Loss: 0.1863
Epoch [25/100] - Train Loss: 0.1653, Val Loss: 0.1849
Epoch [26/100] - Train Loss: 0.1650, Val Loss: 0.1797
Epoch [27/100] - Train Loss: 0.1645, Val Loss: 0.1807
Epoch [28/100] - Train Loss: 0.1639, Val Loss: 0.1791
Epoch [29/100] - Train Loss: 0.1639, Val Loss: 0.1825
Epoch [30/100] - Train Loss: 0.1635, Val Loss: 0.1794
Epoch [31/100] - Train Loss: 0.1633, Val Loss: 0.1817
Epoch [32/100] - Train Loss: 0.1622, Val Loss: 0.1823
Epoch [33/100] - Train Loss: 0.1623, Val Loss: 0.1797
Epoch [34/100] - Train Loss: 0.1619, Val Loss: 0.1756
Epoch [35/100] - Train Loss: 0.1618, Val Loss: 0.1835
Epoch [36/100] - Train Loss: 0.1610, Val Loss: 0.1808
Epoch [37/100] - Train Loss: 0.1611, Val Loss: 0.1775
Epoch [38/100] - Train Loss: 0.1602, Val Loss: 0.1784
Epoch [39/100] - Train Loss: 0.1608, Val Loss: 0.1853
Epoch [40/100] - Train Loss: 0.1605, Val Loss: 0.1763
Epoch [41/100] - Train Loss: 0.1602, Val Loss: 0.1758
Epoch [42/100] - Train Loss: 0.1599, Val Loss: 0.1833
Epoch [43/100] - Train Loss: 0.1595, Val Loss: 0.1820
Epoch [44/100] - Train Loss: 0.1593, Val Loss: 0.1797
Epoch [45/100] - Train Loss: 0.1600, Val Loss: 0.1816
Epoch [46/100] - Train Loss: 0.1589, Val Loss: 0.1852
Epoch [47/100] - Train Loss: 0.1588, Val Loss: 0.1817
Epoch [48/100] - Train Loss: 0.1591, Val Loss: 0.1761
Epoch [49/100] - Train Loss: 0.1587, Val Loss: 0.1738
Epoch [50/100] - Train Loss: 0.1585, Val Loss: 0.1786
Epoch [51/100] - Train Loss: 0.1583, Val Loss: 0.1785
Epoch [52/100] - Train Loss: 0.1585, Val Loss: 0.1818
Epoch [53/100] - Train Loss: 0.1586, Val Loss: 0.1779
Epoch [54/100] - Train Loss: 0.1579, Val Loss: 0.1790
Epoch [55/100] - Train Loss: 0.1575, Val Loss: 0.1771
Epoch [56/100] - Train Loss: 0.1569, Val Loss: 0.1755
Epoch [57/100] - Train Loss: 0.1577, Val Loss: 0.1856
Epoch [58/100] - Train Loss: 0.1571, Val Loss: 0.1828
Epoch [59/100] - Train Loss: 0.1575, Val Loss: 0.1783
Epoch [60/100] - Train Loss: 0.1570, Val Loss: 0.1752
Epoch [61/100] - Train Loss: 0.1568, Val Loss: 0.1760
Epoch [62/100] - Train Loss: 0.1575, Val Loss: 0.1772
Epoch [63/100] - Train Loss: 0.1568, Val Loss: 0.1848
Epoch [64/100] - Train Loss: 0.1567, Val Loss: 0.1856
Epoch [65/100] - Train Loss: 0.1569, Val Loss: 0.1951
Epoch [66/100] - Train Loss: 0.1559, Val Loss: 0.1854
Epoch [67/100] - Train Loss: 0.1565, Val Loss: 0.1873
Epoch [68/100] - Train Loss: 0.1564, Val Loss: 0.1882
Epoch [69/100] - Train Loss: 0.1562, Val Loss: 0.1888
Epoch [70/100] - Train Loss: 0.1563, Val Loss: 0.1919
Epoch [71/100] - Train Loss: 0.1562, Val Loss: 0.1971
Epoch [72/100] - Train Loss: 0.1563, Val Loss: 0.1971
Epoch [73/100] - Train Loss: 0.1564, Val Loss: 0.1849
Epoch [74/100] - Train Loss: 0.1569, Val Loss: 0.1984
Epoch [75/100] - Train Loss: 0.1560, Val Loss: 0.2130
Epoch [76/100] - Train Loss: 0.1560, Val Loss: 0.2147
Epoch [77/100] - Train Loss: 0.1560, Val Loss: 0.1960
Epoch [78/100] - Train Loss: 0.1554, Val Loss: 0.2221
Epoch [79/100] - Train Loss: 0.1568, Val Loss: 0.2226
Epoch [80/100] - Train Loss: 0.1561, Val Loss: 0.2007
Epoch [81/100] - Train Loss: 0.1559, Val Loss: 0.2080
Epoch [82/100] - Train Loss: 0.1564, Val Loss: 0.1982
Epoch [83/100] - Train Loss: 0.1557, Val Loss: 0.2031
Epoch [84/100] - Train Loss: 0.1558, Val Loss: 0.2307
Epoch [85/100] - Train Loss: 0.1552, Val Loss: 0.2220
Epoch [86/100] - Train Loss: 0.1552, Val Loss: 0.2061
Epoch [87/100] - Train Loss: 0.1556, Val Loss: 0.2210
Epoch [88/100] - Train Loss: 0.1548, Val Loss: 0.1925
Epoch [89/100] - Train Loss: 0.1559, Val Loss: 0.2221
Epoch [90/100] - Train Loss: 0.1562, Val Loss: 0.2130
Epoch [91/100] - Train Loss: 0.1551, Val Loss: 0.2305
Epoch [92/100] - Train Loss: 0.1552, Val Loss: 0.2264
Epoch [93/100] - Train Loss: 0.1554, Val Loss: 0.2180
Epoch [94/100] - Train Loss: 0.1546, Val Loss: 0.2424
Epoch [95/100] - Train Loss: 0.1559, Val Loss: 0.2547
Epoch [96/100] - Train Loss: 0.1550, Val Loss: 0.2275
Epoch [97/100] - Train Loss: 0.1556, Val Loss: 0.1935
Epoch [98/100] - Train Loss: 0.1549, Val Loss: 0.2134
Epoch [99/100] - Train Loss: 0.1553, Val Loss: 0.2112
Epoch [100/100] - Train Loss: 0.1547, Val Loss: 0.2198
Fold 5 complete. Validation Accuracy: 0.9415
5-Fold CV Validation Accuracy: Mean = 0.9410, Std = 0.0012
Saved plot of train/val loss per fold to 'cv_all_folds_loss.png'.
Saved mean ± std train/val loss plot to 'cv_mean_confidence_loss.png'.
Evaluating final model on test set...
Final Model Accuracy on Test Set: 0.9415

Classification Report:
              precision    recall  f1-score   support

           1       0.88      0.92      0.90     20000
           2       0.88      0.88      0.88     20000
           3       0.92      0.90      0.91     20000
           4       0.99      0.98      0.99     20000
           5       0.98      0.97      0.98     20000
           6       0.98      0.98      0.98     20000
           7       0.97      0.96      0.96     20000
           8       0.92      0.97      0.95     20000
           9       0.95      0.91      0.93     20000

    accuracy                           0.94    180000
   macro avg       0.94      0.94      0.94    180000
weighted avg       0.94      0.94      0.94    180000

Saved confusion matrix to 'confusion_matrix_nn.png'.
Saved metrics to 'metrics.json'.
Saved final model's state_dict to 'best_model_state.pth'.
Saved final estimator (weights + params) to 'best_estimator.pth'.
Saved detailed log with timestamps to 'log_steps.json'.
All done!
[2025-02-24 09:29:09] Script execution completed successfully.
